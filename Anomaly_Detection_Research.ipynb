{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dự Án Nghiên Cứu: Phát Hiện Bất Thường Ảnh Y Khoa\n",
    "### So sánh hiệu suất giữa U-Net (Baseline) và Reversed Autoencoder (Thử nghiệm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giai đoạn 0: Chuẩn Bị Môi Trường & Dữ Liệu\n",
    "Trong giai đoạn này, chúng ta sẽ thiết lập môi trường làm việc trên Google Colab, kết nối với Google Drive, và tải bộ dữ liệu NIH Chest X-ray từ Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1",
    "outputId": "1"
   },
   "outputs": [],
   "source": [
    "# Kết nối Google Drive (tùy chọn, để lưu model hoặc kaggle.json)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt các thư viện cần thiết\n",
    "!pip install -q pandas scikit-learn matplotlib torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tải dữ liệu từ Kaggle\n",
    "1.  Tạo một API token tại trang Kaggle (`Your Profile` -> `Account` -> `Create New API Token`). Thao tác này sẽ tải về file `kaggle.json`.\n",
    "2.  Upload file `kaggle.json` đó lên Colab bằng đoạn code dưới đây."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2",
    "outputId": "2"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Upload file kaggle.json\n",
    "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
    "    print(\"Vui lòng upload file kaggle.json của bạn.\")\n",
    "    files.upload()\n",
    "\n",
    "# Tạo thư mục và cấp quyền cho file kaggle.json\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3",
    "outputId": "3"
   },
   "outputs": [],
   "source": [
    "# Tải bộ dữ liệu NIH Chest X-ray (chỉ tải file metadata và file ảnh zip nhỏ nhất để demo)\n",
    "# LƯU Ý: Việc tải toàn bộ dữ liệu sẽ mất rất nhiều thời gian và không gian.\n",
    "!kaggle datasets download -d nih-chest-xray/data -f Data_Entry_BBOX.csv\n",
    "!kaggle datasets download -d nih-chest-xray/data -f images_001.zip\n",
    "!kaggle datasets download -d nih-chest-xray/data -f images_002.zip\n",
    "\n",
    "# Giải nén file\n",
    "!unzip -q Data_Entry_BBOX.csv.zip -d .\n",
    "!unzip -q images_001.zip -d .\n",
    "!unzip -q images_002.zip -d ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giai đoạn 1: Khởi Tạo Notebook & Tiền Xử Lý Dữ Liệu\n",
    "### Giới thiệu\n",
    "Trong dự án này, chúng tôi thực hiện một nghiên cứu so sánh để tìm ra kiến trúc hiệu quả cho bài toán phát hiện bất thường không giám sát trên ảnh X-quang ngực. Chiến lược tiếp cận bao gồm hai bước:\n",
    "1.  **Xây dựng mô hình Baseline:** Chúng tôi sẽ triển khai **U-Net**, một kiến trúc đã được chứng minh là cực kỳ hiệu quả cho các tác vụ trên ảnh y khoa, để làm thước đo hiệu suất chuẩn.\n",
    "2.  **Xây dựng mô hình Thử nghiệm:** Dựa trên ý tưởng từ bài báo \"Towards Universal Unsupervised Anomaly Detection...\", chúng tôi sẽ triển khai một kiến trúc **Reversed Autoencoder (RA)**. Mục tiêu là so sánh trực tiếp hiệu suất của RA với U-Net để đánh giá phương pháp mới.\n",
    "\n",
    "Toàn bộ quá trình huấn luyện và đánh giá sẽ được thực hiện trên cùng một tập dữ liệu để đảm bảo tính công bằng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "\n",
    "# --- Cấu hình cho dự án ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMAGE_DIR = \"/content/images\"\n",
    "METADATA_PATH = \"/content/Data_Entry_BBOX.csv\"\n",
    "\n",
    "# Giảm số lượng dữ liệu để chạy demo nhanh hơn\n",
    "NUM_NORMAL_SAMPLES = 2000  # Lấy 2000 ảnh bình thường\n",
    "NUM_ABNORMAL_SAMPLES = 1000 # Lấy 1000 ảnh bất thường cho tập test\n",
    "\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10 # Tăng lên 20-30 cho kết quả tốt hơn\n",
    "LR = 1e-4\n",
    "\n",
    "print(f\"Thiết bị đang sử dụng: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc và lọc dữ liệu\n",
    "df = pd.read_csv(METADATA_PATH)\n",
    "all_image_paths = glob.glob(os.path.join(IMAGE_DIR, '*.png'))\n",
    "image_filenames = {os.path.basename(p): p for p in all_image_paths}\n",
    "\n",
    "df['full_path'] = df['Image Index'].map(image_filenames)\n",
    "df = df.dropna(subset=['full_path'])\n",
    "\n",
    "normal_df = df[df['Finding Labels'] == 'No Finding']\n",
    "abnormal_df = df[df['Finding Labels'] != 'No Finding']\n",
    "\n",
    "# Lấy mẫu dữ liệu\n",
    "normal_df = normal_df.sample(n=NUM_NORMAL_SAMPLES, random_state=42)\n",
    "abnormal_df = abnormal_df.sample(n=NUM_ABNORMAL_SAMPLES, random_state=42)\n",
    "\n",
    "print(f\"Số ảnh bình thường (No Finding): {len(normal_df)}\")\n",
    "print(f\"Số ảnh bất thường: {len(abnormal_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân chia dữ liệu\n",
    "# Tập train và val chỉ chứa ảnh bình thường\n",
    "train_df, val_df = train_test_split(normal_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tập test chứa cả ảnh bình thường và bất thường\n",
    "test_normal_df = val_df.sample(n=int(len(val_df)*0.5), random_state=42) # Lấy 1 nửa val làm test normal\n",
    "test_df = pd.concat([test_normal_df, abnormal_df])\n",
    "\n",
    "print(f\"Kích thước tập Train (chỉ bình thường): {len(train_df)}\")\n",
    "print(f\"Kích thước tập Validation (chỉ bình thường): {len(val_df)}\")\n",
    "print(f\"Kích thước tập Test (bình thường + bất thường): {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết lớp Dataset\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['full_path']\n",
    "        label_str = self.dataframe.iloc[idx]['Finding Labels']\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"L\") # Chuyển sang ảnh xám\n",
    "        \n",
    "        # 0 cho bình thường, 1 cho bất thường\n",
    "        label = 0 if label_str == 'No Finding' else 1\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# Định nghĩa các phép biến đổi\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]) # Chuẩn hóa về [-1, 1]\n",
    "])\n",
    "\n",
    "# Tạo các đối tượng Dataset và DataLoader\n",
    "train_dataset = ChestXrayDataset(train_df, transform=transform)\n",
    "val_dataset = ChestXrayDataset(val_df, transform=transform)\n",
    "test_dataset = ChestXrayDataset(test_df, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giai đoạn 2: Xây Dựng Các Mô Hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A. Mô Hình Baseline: U-Net\n",
    "U-Net là một kiến trúc autoencoder đối xứng với các \"kết nối tắt\" (skip connections). Các kết nối này cho phép thông tin chi tiết từ bộ mã hóa (encoder) được truyền thẳng đến bộ giải mã (decoder), giúp tái tạo hình ảnh sắc nét hơn, đặc biệt quan trọng cho việc định vị các chi tiết nhỏ trong ảnh y khoa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(1, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(256, 512)\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256) # 256 from upconv + 256 from enc3\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128) # 128 from upconv + 128 from enc2\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)   # 64 from upconv + 64 from enc1\n",
    "\n",
    "        # Output layer\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)       # 128x128\n",
    "        p1 = self.pool(e1)      # 64x64\n",
    "        e2 = self.enc2(p1)      # 64x64\n",
    "        p2 = self.pool(e2)      # 32x32\n",
    "        e3 = self.enc3(p2)      # 32x32\n",
    "        p3 = self.pool(e3)      # 16x16\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3) # 16x16\n",
    "\n",
    "        # Decoder\n",
    "        d3 = self.upconv3(b)    # 32x32\n",
    "        d3 = torch.cat((e3, d3), dim=1) # Concatenate with skip connection\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)   # 64x64\n",
    "        d2 = torch.cat((e2, d2), dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)   # 128x128\n",
    "        d1 = torch.cat((e1, d1), dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        output = self.out_conv(d1)\n",
    "        output = self.tanh(output) # Tanh to match normalized input range [-1, 1]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B. Mô Hình Thử Nghiệm: Reversed Autoencoder (RA)\n",
    "Dựa trên ý tưởng của bài báo, RA không chỉ tái tạo lại ảnh gốc, mà cố gắng tạo ra một phiên bản \"giả lành tính\" (pseudo-healthy) của nó. Để mô phỏng sự khác biệt về kiến trúc, chúng tôi triển khai một phiên bản Autoencoder không đối xứng và không có skip-connections đầy đủ như U-Net. Điều này buộc mô hình phải dựa nhiều hơn vào thông tin trong không gian ẩn (bottleneck) để tái tạo, có khả năng sẽ \"bỏ qua\" các chi tiết bất thường mà nó chưa từng học."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReversedAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReversedAutoencoder, self).__init__()\n",
    "        # Encoder: Nén thông tin mạnh mẽ\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # 128 -> 64\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # 64 -> 32\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), # 32 -> 16\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 7) # 16 -> 10\n",
    "        )\n",
    "        \n",
    "        # Decoder: Kiến trúc khác biệt, không đối xứng hoàn toàn\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 7), # 10 -> 16\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 16 -> 32\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # 32 -> 64\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),  # 64 -> 128\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4",
    "outputId": "4"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "print(\"--- Kiến trúc U-Net ---\")\n",
    "unet_model = UNet().to(DEVICE)\n",
    "summary(unet_model, (1, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "print(\"\n--- Kiến trúc Reversed Autoencoder ---\")\n",
    "ra_model = ReversedAutoencoder().to(DEVICE)\n",
    "summary(ra_model, (1, IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giai đoạn 3: Huấn Luyện So Sánh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs, lr, model_name):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for images, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\" ):\n",
    "            images = images.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_train_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, _ in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\" ):\n",
    "                images = images.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, images)\n",
    "                running_val_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {epoch_train_loss:.6f}, Val Loss: {epoch_val_loss:.6f}\")\n",
    "        \n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), f'{model_name}_best.pth')\n",
    "            print(f\"Lưu model tốt nhất: {model_name}_best.pth\")\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A. Huấn luyện U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = UNet().to(DEVICE)\n",
    "unet_model, unet_history = train_model(unet_model, train_loader, val_loader, EPOCHS, LR, \"unet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B. Huấn luyện Reversed Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_model = ReversedAutoencoder().to(DEVICE)\n",
    "ra_model, ra_history = train_model(ra_model, train_loader, val_loader, EPOCHS, LR, \"ra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vẽ đồ thị loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(unet_history['train_loss'], label='U-Net Train Loss')\n",
    "plt.plot(unet_history['val_loss'], label='U-Net Val Loss')\n",
    "plt.title('U-Net Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(ra_history['train_loss'], label='RA Train Loss')\n",
    "plt.plot(ra_history['val_loss'], label='RA Val Loss')\n",
    "plt.title('Reversed Autoencoder Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giai đoạn 4: Phân Tích So Sánh Chuyên Sâu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải lại các model tốt nhất để đánh giá\n",
    "unet_model_eval = UNet().to(DEVICE)\n",
    "unet_model_eval.load_state_dict(torch.load(\"unet_best.pth\"))\n",
    "unet_model_eval.eval()\n",
    "\n",
    "ra_model_eval = ReversedAutoencoder().to(DEVICE)\n",
    "ra_model_eval.load_state_dict(torch.load(\"ra_best.pth\"))\n",
    "ra_model_eval.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    reconstruction_errors = []\n",
    "    true_labels = []\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Tính loss trên từng pixel, sau đó lấy trung bình trên toàn ảnh\n",
    "            error = criterion(outputs, images).mean(dim=[1, 2, 3])\n",
    "            \n",
    "            reconstruction_errors.extend(error.cpu().numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "            \n",
    "    return np.array(reconstruction_errors), np.array(true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4A & 4B. Tính toán hiệu suất cho cả hai mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_errors, unet_labels = evaluate_model(unet_model_eval, test_loader)\n",
    "ra_errors, ra_labels = evaluate_model(ra_model_eval, test_loader)\n",
    "\n",
    "unet_auc = roc_auc_score(unet_labels, unet_errors)\n",
    "ra_auc = roc_auc_score(ra_labels, ra_errors)\n",
    "\n",
    "print(f\"AUC của U-Net: {unet_auc:.4f}\")\n",
    "print(f\"AUC của Reversed Autoencoder: {ra_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4C. Phân Tích So Sánh Trực Tiếp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_fpr, unet_tpr, _ = roc_curve(unet_labels, unet_errors)\n",
    "ra_fpr, ra_tpr, _ = roc_curve(ra_labels, ra_errors)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(unet_fpr, unet_tpr, label=f'U-Net (AUC = {unet_auc:.4f})')\n",
    "plt.plot(ra_fpr, ra_tpr, label=f'Reversed Autoencoder (AUC = {ra_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Đường cong ROC So sánh')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trực quan hóa kết quả so sánh\n",
    "def visualize_comparison(model1, model2, model1_name, model2_name, data_loader, num_images=5):\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    # Lấy một batch ảnh từ test loader\n",
    "    images, labels = next(iter(data_loader))\n",
    "    images = images.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs1 = model1(images)\n",
    "        outputs2 = model2(images)\n",
    "        \n",
    "        error_map1 = torch.mean(criterion(outputs1, images), dim=1).cpu()\n",
    "        error_map2 = torch.mean(criterion(outputs2, images), dim=1).cpu()\n",
    "\n",
    "    images = images.cpu()\n",
    "    outputs1 = outputs1.cpu()\n",
    "    outputs2 = outputs2.cpu()\n",
    "    \n",
    "    plt.figure(figsize=(20, num_images * 4))\n",
    "    for i in range(num_images):\n",
    "        label_text = \"Abnormal\" if labels[i] == 1 else \"Normal\"\n",
    "        \n",
    "        # Denormalize for display\n",
    "        img_display = images[i] * 0.5 + 0.5\n",
    "        recon1_display = outputs1[i] * 0.5 + 0.5\n",
    "        recon2_display = outputs2[i] * 0.5 + 0.5\n",
    "        \n",
    "        # Ảnh gốc\n",
    "        plt.subplot(num_images, 5, i * 5 + 1)\n",
    "        plt.imshow(img_display.squeeze(), cmap='gray')\n",
    "        plt.title(f\"Original ({label_text})\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Tái tạo của Model 1\n",
    "        plt.subplot(num_images, 5, i * 5 + 2)\n",
    "        plt.imshow(recon1_display.squeeze(), cmap='gray')\n",
    "        plt.title(f\"{model1_name} Recon\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Bản đồ lỗi của Model 1\n",
    "        plt.subplot(num_images, 5, i * 5 + 3)\n",
    "        plt.imshow(error_map1[i], cmap='jet')\n",
    "        plt.title(f\"{model1_name} Error Map\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Tái tạo của Model 2\n",
    "        plt.subplot(num_images, 5, i * 5 + 4)\n",
    "        plt.imshow(recon2_display.squeeze(), cmap='gray')\n",
    "        plt.title(f\"{model2_name} Recon\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Bản đồ lỗi của Model 2\n",
    "        plt.subplot(num_images, 5, i * 5 + 5)\n",
    "        plt.imshow(error_map2[i], cmap='jet')\n",
    "        plt.title(f\"{model2_name} Error Map\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_comparison(unet_model_eval, ra_model_eval, \"U-Net\", \"RA\", test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giai đoạn 5: Tổng Kết Dựa Trên So Sánh\n",
    "Trong phần này, bạn sẽ viết kết luận cuối cùng của mình.\n",
    "\n",
    "1.  **Tóm tắt quá trình:** Tóm tắt lại việc đã xây dựng và so sánh hai mô hình U-Net và Reversed Autoencoder cho bài toán phát hiện bất thường.\n",
    "2.  **Phân tích kết quả:** Dựa vào điểm AUC và các hình ảnh trực quan hóa, hãy đưa ra kết luận mô hình nào hoạt động hiệu quả hơn. Ví dụ: \"Mặc dù cả hai mô hình đều cho thấy khả năng phát hiện bất thường, U-Net với AUC cao hơn và bản đồ lỗi chi tiết hơn đã chứng tỏ sự vượt trội. Các kết nối tắt (skip connections) của U-Net dường như đóng vai trò quan trọng trong việc tái tạo các chi tiết nền của ảnh, giúp làm nổi bật các vùng lỗi thực sự do bất thường gây ra.\"\n",
    "3.  **Hạn chế:** Nêu ra các hạn chế của nghiên cứu (ví dụ: chỉ dùng một phần nhỏ dữ liệu, thời gian huấn luyện ngắn).\n",
    "4.  **Hướng phát triển:** Đề xuất các bước tiếp theo (ví dụ: huấn luyện trên toàn bộ dữ liệu, thử nghiệm với các hàm loss khác, áp dụng lên bộ dữ liệu MRI đã tải về)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}