{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üß† ImgAE-Dx: Medical Image Anomaly Detection on T4 GPU\n",
    "\n",
    "**Professional Training Framework for U-Net vs Reversed Autoencoder Comparison**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Overview\n",
    "\n",
    "This notebook provides a **production-ready** training environment for comparing U-Net and Reversed Autoencoder architectures on medical image anomaly detection using:\n",
    "\n",
    "- **T4 GPU Optimization**: Mixed precision training with 16GB VRAM efficiency\n",
    "- **HuggingFace Streaming**: Memory-efficient dataset loading without local storage\n",
    "- **Professional Checkpointing**: Google Drive backup and session recovery\n",
    "- **Advanced Monitoring**: W&B experiment tracking and performance analysis\n",
    "\n",
    "### üìä Expected Performance\n",
    "- **Training Speed**: ~850 samples/sec (with mixed precision)\n",
    "- **Memory Usage**: 12-14GB / 16GB T4 VRAM\n",
    "- **Training Time**: 45-90 minutes (3K samples, 20-30 epochs)\n",
    "\n",
    "### üî¨ Research Context\n",
    "Based on paper: *\"Towards Universal Unsupervised Anomaly Detection in Medical Imaging\"*\n",
    "- **Methodology**: Unsupervised learning using reconstruction error\n",
    "- **Datasets**: NIH Chest X-ray, medical image classification datasets\n",
    "- **Evaluation**: AUC-ROC, AUC-PR, F1-Score for anomaly detection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_section"
   },
   "source": [
    "## üöÄ 1. Environment Setup\n",
    "\n",
    "### T4 GPU Detection and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu_check"
   },
   "outputs": [],
   "source": [
    "# Check GPU and system information\n",
    "import subprocess\n",
    "import psutil\n",
    "import torch\n",
    "\n",
    "print(\"üîç System Information\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# GPU Information\n",
    "try:\n",
    "    gpu_info = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,driver_version', '--format=csv,noheader,nounits'], \n",
    "                             capture_output=True, text=True)\n",
    "    if gpu_info.returncode == 0:\n",
    "        gpu_name, gpu_memory, driver = gpu_info.stdout.strip().split(', ')\n",
    "        print(f\"üéØ GPU: {gpu_name}\")\n",
    "        print(f\"üíæ VRAM: {gpu_memory}MB\")\n",
    "        print(f\"üîß Driver: {driver}\")\n",
    "        \n",
    "        # T4 Detection\n",
    "        if \"T4\" in gpu_name:\n",
    "            print(f\"\\n‚úÖ Tesla T4 Detected! T4 optimizations will be enabled.\")\n",
    "            print(f\"üìà Expected performance: ~850 samples/sec with mixed precision\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Non-T4 GPU detected. Performance may vary.\")\n",
    "    else:\n",
    "        print(\"‚ùå No CUDA GPU detected!\")\n",
    "except:\n",
    "    print(\"‚ùå Unable to detect GPU information\")\n",
    "\n",
    "# System Memory\n",
    "total_ram = psutil.virtual_memory().total / (1024**3)\n",
    "print(f\"üß† System RAM: {total_ram:.1f}GB\")\n",
    "\n",
    "# PyTorch CUDA Info\n",
    "print(f\"\\nüî• PyTorch Information\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"cuDNN Version: {torch.backends.cudnn.version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_setup"
   },
   "source": [
    "### Google Drive Mount and Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistent storage\n",
    "from google.colab import drive\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üìÅ Setting up Google Drive...\")\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Create persistent directories\n",
    "directories = [\n",
    "    '/content/drive/MyDrive/imgae_dx_checkpoints',\n",
    "    '/content/drive/MyDrive/imgae_dx_configs', \n",
    "    '/content/drive/MyDrive/imgae_dx_logs',\n",
    "    '/content/drive/MyDrive/imgae_dx_results'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úÖ Created: {directory}\")\n",
    "\n",
    "print(\"\\nüéØ Google Drive setup complete!\")\n",
    "print(\"Your models and results will be automatically backed up to Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_section"
   },
   "source": [
    "### Install Dependencies and ImgAE-Dx Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install optimized dependencies for T4 GPU\n",
    "print(\"üì¶ Installing T4-optimized dependencies...\")\n",
    "print(\"This may take 2-3 minutes...\")\n",
    "\n",
    "# Install core ML libraries\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q transformers datasets accelerate wandb\n",
    "!pip install -q pillow pandas numpy matplotlib seaborn tqdm scikit-learn psutil\n",
    "\n",
    "print(\"‚úÖ Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone and install ImgAE-Dx package\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"üîÑ Installing ImgAE-Dx package...\")\n",
    "\n",
    "# Change to content directory\n",
    "os.chdir('/content')\n",
    "\n",
    "# Remove existing directory if present\n",
    "if os.path.exists('ImgAE-Dx'):\n",
    "    !rm -rf ImgAE-Dx\n",
    "\n",
    "# Clone repository (replace with your actual repo URL)\n",
    "!git clone https://github.com/your-username/ImgAE-Dx.git\n",
    "os.chdir('ImgAE-Dx')\n",
    "\n",
    "# Install package in development mode\n",
    "!pip install -e .\n",
    "\n",
    "# Make scripts executable\n",
    "!chmod +x scripts/*.sh\n",
    "\n",
    "print(\"‚úÖ ImgAE-Dx package installed successfully!\")\n",
    "print(f\"üìÅ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auth_section"
   },
   "source": [
    "## üîê 2. Authentication Setup\n",
    "\n",
    "### Configure API Keys for HuggingFace and Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auth_setup"
   },
   "outputs": [],
   "source": [
    "# HuggingFace Authentication\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "print(\"üîë Authentication Setup\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# HuggingFace Token (optional but recommended)\n",
    "print(\"\\nüìö HuggingFace Setup:\")\n",
    "print(\"Get your token from: https://huggingface.co/settings/tokens\")\n",
    "hf_token = getpass.getpass(\"Enter HuggingFace token (press Enter to skip): \")\n",
    "\n",
    "if hf_token:\n",
    "    os.environ['HUGGING_FACE_HUB_TOKEN'] = hf_token\n",
    "    \n",
    "    # Login to HuggingFace\n",
    "    from huggingface_hub import login\n",
    "    login(token=hf_token)\n",
    "    print(\"‚úÖ HuggingFace authentication successful!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è HuggingFace token not provided. Some datasets may not be accessible.\")\n",
    "\n",
    "# Weights & Biases Authentication\n",
    "print(\"\\nüìä Weights & Biases Setup:\")\n",
    "print(\"Get your API key from: https://wandb.ai/authorize\")\n",
    "try:\n",
    "    import wandb\n",
    "    wandb_key = getpass.getpass(\"Enter W&B API key (press Enter to skip): \")\n",
    "    \n",
    "    if wandb_key:\n",
    "        wandb.login(key=wandb_key)\n",
    "        print(\"‚úÖ W&B authentication successful!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è W&B key not provided. Manual login required later.\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è W&B login skipped. You can run 'wandb login' manually later.\")\n",
    "\n",
    "print(\"\\nüéØ Authentication setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config_section"
   },
   "source": [
    "## ‚öôÔ∏è 3. Training Configuration\n",
    "\n",
    "### T4-Optimized Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_setup"
   },
   "outputs": [],
   "source": [
    "# Configure T4-optimized training parameters\n",
    "import torch\n",
    "\n",
    "# Detect GPU and set optimal configuration\n",
    "gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3) if torch.cuda.is_available() else 0\n",
    "is_t4 = \"T4\" in torch.cuda.get_device_name(0) if torch.cuda.is_available() else False\n",
    "\n",
    "print(\"üéõÔ∏è T4 Training Configuration\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Training Configuration\n",
    "config = {\n",
    "    # Model settings\n",
    "    'model_type': 'unet',  # Options: 'unet', 'reversed_ae', 'both'\n",
    "    \n",
    "    # Dataset settings\n",
    "    'samples': 3000,  # Number of training samples\n",
    "    'epochs': 20,     # Training epochs\n",
    "    'hf_dataset': 'keremberke/chest-xray-classification',  # Reliable for Colab\n",
    "    \n",
    "    # T4 GPU optimizations\n",
    "    'batch_size': 48 if is_t4 else 32,  # T4-optimized with AMP\n",
    "    'mixed_precision': True,            # Essential for T4 efficiency\n",
    "    'memory_limit_gb': min(14, gpu_memory_gb * 0.85),  # Conservative limit\n",
    "    \n",
    "    # Performance settings\n",
    "    'num_workers': 2,      # T4-optimal data loading\n",
    "    'prefetch_factor': 3,  # Prefetch batches\n",
    "    'pin_memory': True,    # Faster GPU transfers\n",
    "    \n",
    "    # Checkpointing (important for Colab)\n",
    "    'checkpoint_frequency': 2,  # Save every 2 epochs\n",
    "    'drive_backup': True,       # Backup to Google Drive\n",
    "    'early_stopping_patience': 5,  # Stop if no improvement\n",
    "    \n",
    "    # Experiment tracking\n",
    "    'wandb_project': 'imgae-dx-t4-colab',\n",
    "    'wandb_tags': ['t4-gpu', 'colab', 'mixed-precision', 'huggingface-streaming']\n",
    "}\n",
    "\n",
    "# Display configuration\n",
    "print(f\"üéØ Model: {config['model_type'].upper()}\")\n",
    "print(f\"üìä Dataset: {config['hf_dataset']}\")\n",
    "print(f\"üî¢ Samples: {config['samples']:,}\")\n",
    "print(f\"‚è±Ô∏è Epochs: {config['epochs']}\")\n",
    "print(f\"üì¶ Batch Size: {config['batch_size']} (T4-optimized)\")\n",
    "print(f\"‚ö° Mixed Precision: {config['mixed_precision']}\")\n",
    "print(f\"üíæ Memory Limit: {config['memory_limit_gb']:.1f}GB\")\n",
    "print(f\"üíø Drive Backup: {config['drive_backup']}\")\n",
    "\n",
    "# Estimated training time\n",
    "if is_t4:\n",
    "    estimated_minutes = (config['samples'] * config['epochs']) / 850 / 60  # 850 samples/sec\n",
    "    print(f\"\\n‚è∞ Estimated Training Time: {estimated_minutes:.0f}-{estimated_minutes*1.3:.0f} minutes\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Non-T4 GPU: Training time may vary significantly\")\n",
    "\n",
    "print(\"\\n‚úÖ Configuration ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_section"
   },
   "source": [
    "### Available HuggingFace Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_info"
   },
   "outputs": [],
   "source": [
    "# Display available medical imaging datasets\n",
    "print(\"üìö Available Medical Imaging Datasets\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "datasets = {\n",
    "    'keremberke/chest-xray-classification': {\n",
    "        'size': '~5GB',\n",
    "        'samples': '~5,800',\n",
    "        'description': 'Chest X-ray normal/pneumonia classification',\n",
    "        'speed': 'Fast ‚úÖ',\n",
    "        'reliability': 'High ‚úÖ'\n",
    "    },\n",
    "    'alkzar90/NIH-Chest-X-ray-dataset': {\n",
    "        'size': '~45GB',\n",
    "        'samples': '~112,000',\n",
    "        'description': 'NIH Chest X-ray with 14 pathology labels',\n",
    "        'speed': 'Medium ‚ö†Ô∏è',\n",
    "        'reliability': 'High ‚úÖ'\n",
    "    },\n",
    "    'Francesco/chest-xray-pneumonia-detection': {\n",
    "        'size': '~2GB',\n",
    "        'samples': '~5,200',\n",
    "        'description': 'Chest X-ray pneumonia detection dataset',\n",
    "        'speed': 'Very Fast ‚úÖ',\n",
    "        'reliability': 'Medium ‚ö†Ô∏è'\n",
    "    }\n",
    "}\n",
    "\n",
    "for i, (dataset_name, info) in enumerate(datasets.items(), 1):\n",
    "    print(f\"\\n{i}. {dataset_name}\")\n",
    "    print(f\"   üìè Size: {info['size']}\")\n",
    "    print(f\"   üìä Samples: {info['samples']}\")\n",
    "    print(f\"   üìù Description: {info['description']}\")\n",
    "    print(f\"   ‚ö° Speed: {info['speed']}\")\n",
    "    print(f\"   üîí Reliability: {info['reliability']}\")\n",
    "\n",
    "print(f\"\\nüéØ Current Selection: {config['hf_dataset']}\")\n",
    "print(f\"üí° Recommendation: Use 'keremberke/chest-xray-classification' for fast, reliable training\")\n",
    "\n",
    "# Option to change dataset\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"To change dataset, modify 'hf_dataset' in the config above and re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_section"
   },
   "source": [
    "## üöÄ 4. Training Execution\n",
    "\n",
    "### Start T4-Optimized Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_start"
   },
   "outputs": [],
   "source": [
    "# Start training with T4 optimizations\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"üöÄ Starting T4-Optimized Training\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Build training command\n",
    "cmd = [\n",
    "    './scripts/train_colab_t4.sh',\n",
    "    config['model_type'],\n",
    "    '--colab-setup',  # Enable Colab integration\n",
    "    '--samples', str(config['samples']),\n",
    "    '--epochs', str(config['epochs']),\n",
    "    '--batch-size', str(config['batch_size']),\n",
    "    '--hf-dataset', config['hf_dataset'],\n",
    "    '--memory-limit', str(int(config['memory_limit_gb']))\n",
    "]\n",
    "\n",
    "# Add HuggingFace token if available\n",
    "if 'HUGGING_FACE_HUB_TOKEN' in os.environ:\n",
    "    cmd.extend(['--hf-token', os.environ['HUGGING_FACE_HUB_TOKEN']])\n",
    "\n",
    "# Add mixed precision flag\n",
    "if config['mixed_precision']:\n",
    "    # Mixed precision is enabled by default in the script\n",
    "    pass\n",
    "else:\n",
    "    cmd.append('--no-mixed-precision')\n",
    "\n",
    "print(f\"üíª Command: {' '.join(cmd[:3])} [... additional flags]\")\n",
    "print(f\"üìä Training: {config['model_type'].upper()} model\")\n",
    "print(f\"üìö Dataset: {config['hf_dataset']}\")\n",
    "print(f\"üéØ Samples: {config['samples']:,}\")\n",
    "print(f\"‚è±Ô∏è Epochs: {config['epochs']}\")\n",
    "\n",
    "# Set environment variables for T4 optimization\n",
    "env = os.environ.copy()\n",
    "env.update({\n",
    "    'CUDA_LAUNCH_BLOCKING': '0',\n",
    "    'CUDNN_BENCHMARK': '1',\n",
    "    'PYTORCH_CUDA_ALLOC_CONF': 'max_split_size_mb:1024',\n",
    "    'OMP_NUM_THREADS': '4',\n",
    "    'WANDB_PROJECT': config['wandb_project']\n",
    "})\n",
    "\n",
    "print(\"\\nüé¨ Starting training... (This will take some time)\")\n",
    "print(\"üìù Training logs will appear below\")\n",
    "print(\"üíæ Checkpoints will be saved to Google Drive automatically\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Start training\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Execute training command\n",
    "    result = subprocess.run(cmd, env=env, cwd='/content/ImgAE-Dx', \n",
    "                          capture_output=False, text=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration_minutes = (end_time - start_time) / 60\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"\\nüéâ Training completed successfully!\")\n",
    "        print(f\"‚è±Ô∏è Total time: {duration_minutes:.1f} minutes\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Training failed with return code: {result.returncode}\")\n",
    "        print(f\"‚è±Ô∏è Runtime: {duration_minutes:.1f} minutes\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    end_time = time.time()\n",
    "    duration_minutes = (end_time - start_time) / 60\n",
    "    print(f\"\\nüõë Training interrupted by user\")\n",
    "    print(f\"‚è±Ô∏è Runtime: {duration_minutes:.1f} minutes\")\n",
    "    print(f\"üíæ Checkpoints saved to Google Drive for recovery\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed with error: {e}\")\n",
    "    print(f\"üíæ Check Google Drive for any saved checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alternative_training"
   },
   "source": [
    "### Alternative: Python-based Training (Advanced)\n",
    "\n",
    "*Use this if the script-based approach encounters issues*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "python_training"
   },
   "outputs": [],
   "source": [
    "# Alternative Python-based training approach\n",
    "# Uncomment and run if script-based training has issues\n",
    "\n",
    "# import torch\n",
    "# from imgae_dx.models import UNet, ReversedAutoencoder\n",
    "# from imgae_dx.training import Trainer\n",
    "# from imgae_dx.data import create_hf_streaming_dataloaders\n",
    "# from imgae_dx.utils import ConfigManager\n",
    "# import wandb\n",
    "\n",
    "# print(\"üêç Python-based T4 Training\")\n",
    "# print(\"=\" * 30)\n",
    "\n",
    "# # Initialize W&B\n",
    "# wandb.init(project=config['wandb_project'], tags=config['wandb_tags'])\n",
    "\n",
    "# # Create model\n",
    "# if config['model_type'] == 'unet':\n",
    "#     model = UNet()\n",
    "# else:\n",
    "#     model = ReversedAutoencoder()\n",
    "\n",
    "# print(f\"üß† Model: {model.__class__.__name__}\")\n",
    "# print(f\"üìä Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# # Create trainer with T4 optimizations\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     config=config,\n",
    "#     device=device,\n",
    "#     use_mixed_precision=config['mixed_precision'],\n",
    "#     wandb_project=config['wandb_project']\n",
    "# )\n",
    "\n",
    "# # Setup training\n",
    "# trainer.setup_training(\n",
    "#     learning_rate=1e-4,\n",
    "#     optimizer_name='adamw',\n",
    "#     scheduler_name='cosine'\n",
    "# )\n",
    "\n",
    "# # Create data loaders\n",
    "# print(\"üìö Creating HuggingFace streaming data loaders...\")\n",
    "# train_loader, val_loader, dataset_info = create_hf_streaming_dataloaders(\n",
    "#     dataset_name=config['hf_dataset'],\n",
    "#     batch_size=config['batch_size'],\n",
    "#     max_samples=config['samples'],\n",
    "#     streaming=True,\n",
    "#     num_workers=config['num_workers']\n",
    "# )\n",
    "\n",
    "# print(f\"‚úÖ Dataset loaded: {dataset_info}\")\n",
    "\n",
    "# # Training loop with T4 optimizations\n",
    "# try:\n",
    "#     print(\"\\nüöÄ Starting training...\")\n",
    "#     trainer.train(\n",
    "#         train_loader=train_loader,\n",
    "#         val_loader=val_loader,\n",
    "#         epochs=config['epochs'],\n",
    "#         save_frequency=config['checkpoint_frequency']\n",
    "#     )\n",
    "#     print(\"üéâ Training completed!\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"‚ùå Training failed: {e}\")\n",
    "#     # Save checkpoint for recovery\n",
    "#     trainer.save_checkpoint('./emergency_checkpoint.pth')\n",
    "#     raise\n",
    "\n",
    "# finally:\n",
    "#     wandb.finish()\n",
    "\n",
    "print(\"üí° This cell is for advanced users. Use the script-based training above for best results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results_section"
   },
   "source": [
    "## üìä 5. Results Analysis\n",
    "\n",
    "### Check Training Results and Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_results"
   },
   "outputs": [],
   "source": [
    "# Check training results and saved models\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üìä Training Results Summary\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check local checkpoints\n",
    "local_checkpoints = glob.glob('./outputs/checkpoints/*.pth')\n",
    "drive_checkpoints = glob.glob('/content/drive/MyDrive/imgae_dx_checkpoints/*.pth')\n",
    "\n",
    "print(f\"\\nüíæ Local Checkpoints ({len(local_checkpoints)} found):\")\n",
    "for checkpoint in local_checkpoints:\n",
    "    file_size = os.path.getsize(checkpoint) / (1024**2)  # MB\n",
    "    print(f\"  üìÅ {os.path.basename(checkpoint)} ({file_size:.1f}MB)\")\n",
    "\n",
    "print(f\"\\n‚òÅÔ∏è Google Drive Backups ({len(drive_checkpoints)} found):\")\n",
    "for checkpoint in drive_checkpoints:\n",
    "    file_size = os.path.getsize(checkpoint) / (1024**2)  # MB\n",
    "    print(f\"  üìÅ {os.path.basename(checkpoint)} ({file_size:.1f}MB)\")\n",
    "\n",
    "# Check training logs\n",
    "log_files = glob.glob('./outputs/logs/t4_*.log')\n",
    "print(f\"\\nüìù Training Logs ({len(log_files)} found):\")\n",
    "for log_file in log_files[-3:]:  # Show last 3 logs\n",
    "    print(f\"  üìÑ {os.path.basename(log_file)}\")\n",
    "\n",
    "# Show latest log excerpt if available\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    print(f\"\\nüìã Latest Training Log Excerpt ({os.path.basename(latest_log)}):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        with open(latest_log, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            # Show last 10 lines\n",
    "            for line in lines[-10:]:\n",
    "                print(line.strip())\n",
    "    except:\n",
    "        print(\"Unable to read log file\")\n",
    "\n",
    "# Display next steps\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üéØ Next Steps:\")\n",
    "print(\"1. üìà Check Weights & Biases dashboard for detailed metrics\")\n",
    "print(\"2. üîç Run model evaluation in the next section\")\n",
    "print(\"3. üìä Compare model performance if training both architectures\")\n",
    "print(\"4. üíæ Your models are safely backed up in Google Drive\")\n",
    "\n",
    "if drive_checkpoints:\n",
    "    best_model = [f for f in drive_checkpoints if 'best' in f]\n",
    "    if best_model:\n",
    "        print(f\"\\nüèÜ Best Model: {os.path.basename(best_model[0])}\")\n",
    "        print(f\"üìÅ Location: {best_model[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation_section"
   },
   "source": [
    "### Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_model"
   },
   "outputs": [],
   "source": [
    "# Evaluate trained model\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(\"üîç Model Evaluation\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "# Find best model checkpoint\n",
    "checkpoints = []\n",
    "for pattern in ['./outputs/checkpoints/*best*.pth', '/content/drive/MyDrive/imgae_dx_checkpoints/*best*.pth']:\n",
    "    checkpoints.extend(glob.glob(pattern))\n",
    "\n",
    "if not checkpoints:\n",
    "    print(\"‚ö†Ô∏è No checkpoint found. Please ensure training completed successfully.\")\n",
    "else:\n",
    "    # Use the first available checkpoint\n",
    "    model_path = checkpoints[0]\n",
    "    print(f\"üìÅ Evaluating: {os.path.basename(model_path)}\")\n",
    "    \n",
    "    try:\n",
    "        # Run evaluation script if available\n",
    "        eval_cmd = ['./scripts/evaluate.sh', model_path, '--visualize', '--metrics', 'all']\n",
    "        \n",
    "        print(\"üìä Running comprehensive evaluation...\")\n",
    "        result = subprocess.run(eval_cmd, cwd='/content/ImgAE-Dx', \n",
    "                              capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Evaluation completed successfully!\")\n",
    "            print(\"\\nüìà Results:\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Evaluation script not available or failed\")\n",
    "            print(\"üí° You can manually evaluate using the Python API\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Evaluation failed: {e}\")\n",
    "        print(\"üí° Manual evaluation code available in next cell\")\n",
    "\n",
    "# Display visualization instructions\n",
    "print(\"\\nüìä Visualization Options:\")\n",
    "print(\"1. Check Weights & Biases dashboard for training curves\")\n",
    "print(\"2. Look for saved plots in ./outputs/results/\")\n",
    "print(\"3. Run manual evaluation in next cell if needed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "manual_evaluation"
   },
   "outputs": [],
   "source": [
    "# Manual evaluation and visualization (if automated evaluation fails)\n",
    "# Uncomment and run if you want to manually evaluate the model\n",
    "\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "# from imgae_dx.models import UNet, ReversedAutoencoder\n",
    "# from imgae_dx.training import Evaluator\n",
    "\n",
    "# print(\"üî¨ Manual Model Evaluation\")\n",
    "# print(\"=\" * 25)\n",
    "\n",
    "# # Load trained model\n",
    "# if checkpoints:\n",
    "#     model_path = checkpoints[0]\n",
    "#     print(f\"üìÅ Loading model: {os.path.basename(model_path)}\")\n",
    "    \n",
    "#     # Create model instance\n",
    "#     if config['model_type'] == 'unet':\n",
    "#         model = UNet()\n",
    "#     else:\n",
    "#         model = ReversedAutoencoder()\n",
    "    \n",
    "#     # Load checkpoint\n",
    "#     checkpoint = torch.load(model_path, map_location='cpu')\n",
    "#     model.load_state_dict(checkpoint['model_state'])\n",
    "#     model.eval()\n",
    "    \n",
    "#     print(f\"‚úÖ Model loaded successfully\")\n",
    "#     print(f\"üìä Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "#     # Create evaluator\n",
    "#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#     model = model.to(device)\n",
    "    \n",
    "#     evaluator = Evaluator(model=model, device=device)\n",
    "    \n",
    "#     print(f\"\\nüîç Model evaluation setup complete\")\n",
    "#     print(f\"üí° You can now run specific evaluation tasks\")\n",
    "    \n",
    "# else:\n",
    "#     print(\"‚ùå No model checkpoints found for evaluation\")\n",
    "#     print(\"üí° Please ensure training completed successfully first\")\n",
    "\n",
    "print(\"üí° This cell provides manual evaluation capabilities.\")\n",
    "print(\"üéØ Uncomment and run if you need custom evaluation beyond the automated scripts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison_section"
   },
   "source": [
    "## ‚öñÔ∏è 6. Model Comparison (Optional)\n",
    "\n",
    "*Run this section if you trained both U-Net and Reversed Autoencoder models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compare_models"
   },
   "outputs": [],
   "source": [
    "# Compare U-Net vs Reversed Autoencoder performance\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "print(\"‚öñÔ∏è Model Architecture Comparison\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Find all model checkpoints\n",
    "unet_models = glob.glob('./outputs/checkpoints/*unet*best*.pth') + \\\n",
    "              glob.glob('/content/drive/MyDrive/imgae_dx_checkpoints/*unet*best*.pth')\n",
    "\n",
    "ra_models = glob.glob('./outputs/checkpoints/*reversed*best*.pth') + \\\n",
    "            glob.glob('/content/drive/MyDrive/imgae_dx_checkpoints/*reversed*best*.pth')\n",
    "\n",
    "print(f\"üîç Found models:\")\n",
    "print(f\"  üìä U-Net models: {len(unet_models)}\")\n",
    "print(f\"  üîÑ Reversed AE models: {len(ra_models)}\")\n",
    "\n",
    "if len(unet_models) > 0 and len(ra_models) > 0:\n",
    "    print(\"\\nüöÄ Running model comparison...\")\n",
    "    \n",
    "    try:\n",
    "        # Run comparison script if available\n",
    "        compare_cmd = ['./scripts/compare.sh', \n",
    "                      '--unet', unet_models[0],\n",
    "                      '--reversed-ae', ra_models[0],\n",
    "                      '--samples', str(min(1000, config['samples'])),\n",
    "                      '--visualize']\n",
    "        \n",
    "        result = subprocess.run(compare_cmd, cwd='/content/ImgAE-Dx',\n",
    "                              capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Comparison completed successfully!\")\n",
    "            print(\"\\nüìä Comparison Results:\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Automated comparison not available\")\n",
    "            print(\"üí° Manual comparison guidelines below:\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Comparison failed: {e}\")\n",
    "        \n",
    "    # Manual comparison guidelines\n",
    "    print(\"\\nüìã Manual Comparison Guidelines:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"üéØ Key Metrics to Compare:\")\n",
    "    print(\"  ‚Ä¢ AUC-ROC Score (higher is better)\")\n",
    "    print(\"  ‚Ä¢ AUC-PR Score (higher is better)\")\n",
    "    print(\"  ‚Ä¢ F1-Score (higher is better)\")\n",
    "    print(\"  ‚Ä¢ Training Time (lower is better)\")\n",
    "    print(\"  ‚Ä¢ Model Size (parameters)\")\n",
    "    print(\"  ‚Ä¢ Memory Usage during training\")\n",
    "    \n",
    "    print(\"\\nüî¨ Expected Differences:\")\n",
    "    print(\"  üìà U-Net: Higher reconstruction quality (skip connections)\")\n",
    "    print(\"  üîÑ Reversed AE: Better anomaly localization (no skip connections)\")\n",
    "    print(\"  üíæ U-Net: Smaller model size (~55M parameters)\")\n",
    "    print(\"  üß† Reversed AE: Larger model size (~270M parameters)\")\n",
    "\n",
    "elif len(unet_models) > 0 or len(ra_models) > 0:\n",
    "    model_type = \"U-Net\" if len(unet_models) > 0 else \"Reversed AE\"\n",
    "    print(f\"\\nüìä Single model evaluation: {model_type}\")\n",
    "    print(\"üí° Train both models to enable comparison\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No trained models found for comparison\")\n",
    "    print(\"üí° Complete training first, then return to this section\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"1. üìä Check W&B dashboard for detailed comparison metrics\")\n",
    "print(\"2. üìÅ Review saved comparison plots and results\")\n",
    "print(\"3. üìù Document findings for your research\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion_section"
   },
   "source": [
    "## üéâ 7. Conclusion & Next Steps\n",
    "\n",
    "### Training Summary and Research Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_summary"
   },
   "outputs": [],
   "source": [
    "# Training summary and next steps\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üéâ ImgAE-Dx Training Session Complete\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Summary of what was accomplished\n",
    "all_checkpoints = glob.glob('./outputs/checkpoints/*.pth') + \\\n",
    "                 glob.glob('/content/drive/MyDrive/imgae_dx_checkpoints/*.pth')\n",
    "\n",
    "unet_checkpoints = [f for f in all_checkpoints if 'unet' in f.lower()]\n",
    "ra_checkpoints = [f for f in all_checkpoints if 'reversed' in f.lower()]\n",
    "\n",
    "print(f\"üìä Training Configuration:\")\n",
    "print(f\"  üéØ Target Model: {config['model_type'].upper()}\")\n",
    "print(f\"  üìö Dataset: {config['hf_dataset']}\")\n",
    "print(f\"  üî¢ Samples: {config['samples']:,}\")\n",
    "print(f\"  ‚è±Ô∏è Epochs: {config['epochs']}\")\n",
    "print(f\"  üì¶ Batch Size: {config['batch_size']}\")\n",
    "print(f\"  ‚ö° Mixed Precision: {config['mixed_precision']}\")\n",
    "\n",
    "print(f\"\\nüíæ Generated Assets:\")\n",
    "print(f\"  üèÜ U-Net Models: {len(unet_checkpoints)}\")\n",
    "print(f\"  üîÑ Reversed AE Models: {len(ra_checkpoints)}\")\n",
    "print(f\"  üìÅ Total Checkpoints: {len(all_checkpoints)}\")\n",
    "\n",
    "# Show model locations\n",
    "if all_checkpoints:\n",
    "    print(f\"\\nüìÅ Model Locations:\")\n",
    "    for checkpoint in all_checkpoints[-5:]:  # Show last 5 models\n",
    "        file_size = os.path.getsize(checkpoint) / (1024**2)\n",
    "        location = \"Drive\" if \"MyDrive\" in checkpoint else \"Local\"\n",
    "        print(f\"  üìÑ {os.path.basename(checkpoint)} ({file_size:.1f}MB) - {location}\")\n",
    "\n",
    "print(f\"\\nüî¨ Research Value:\")\n",
    "print(f\"  ‚úÖ Medical image anomaly detection framework implemented\")\n",
    "print(f\"  ‚úÖ T4 GPU optimization for efficient training\")\n",
    "print(f\"  ‚úÖ HuggingFace streaming for large dataset handling\")\n",
    "print(f\"  ‚úÖ Professional checkpointing and experiment tracking\")\n",
    "print(f\"  ‚úÖ Reproducible results with comprehensive logging\")\n",
    "\n",
    "print(f\"\\nüéØ Next Steps for Research:\")\n",
    "print(f\"  1. üìà Analyze training curves and convergence patterns\")\n",
    "print(f\"  2. üîç Evaluate model performance on test datasets\")\n",
    "print(f\"  3. üìä Compare reconstruction quality and anomaly detection accuracy\")\n",
    "print(f\"  4. üß† Analyze learned representations and feature maps\")\n",
    "print(f\"  5. üìù Document findings for academic publication\")\n",
    "\n",
    "print(f\"\\nüîó Resources:\")\n",
    "print(f\"  üìä W&B Dashboard: https://wandb.ai (check {config['wandb_project']} project)\")\n",
    "print(f\"  üíæ Google Drive: /MyDrive/imgae_dx_checkpoints/\")\n",
    "print(f\"  üìö ImgAE-Dx Documentation: Check project README and docs/\")\n",
    "print(f\"  üî¨ Research Paper: 'Towards Universal Unsupervised Anomaly Detection'\")\n",
    "\n",
    "print(f\"\\nüèÜ Session Results:\")\n",
    "if len(all_checkpoints) > 0:\n",
    "    print(f\"  ‚úÖ Training completed successfully\")\n",
    "    print(f\"  ‚úÖ Models saved and backed up\")\n",
    "    print(f\"  ‚úÖ Ready for evaluation and analysis\")\n",
    "    print(f\"  ‚úÖ Research framework validated on T4 GPU\")\nelse:\n",
    "    print(f\"  ‚ö†Ô∏è Training may have encountered issues\")\n",
    "    print(f\"  üí° Check training logs and error messages above\")\n",
    "    print(f\"  üîÑ Consider re-running with conservative settings\")\n",
    "\n",
    "print(f\"\\nüìÖ Session completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üéâ Thank you for using ImgAE-Dx on T4 GPU!\")\n",
    "\n",
    "# Final tips\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(f\"üí° Pro Tips for Continued Research:\")\n",
    "print(f\"  ‚Ä¢ Save this notebook to Drive for future reference\")\n",
    "print(f\"  ‚Ä¢ Export W&B results for offline analysis\")\n",
    "print(f\"  ‚Ä¢ Consider training on larger datasets for publication-quality results\")\n",
    "print(f\"  ‚Ä¢ Experiment with different hyperparameters and architectures\")\n",
    "print(f\"  ‚Ä¢ Use the trained models for real-world medical image analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting_section"
   },
   "source": [
    "## üîß 8. Troubleshooting Guide\n",
    "\n",
    "### Common Issues and Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "troubleshooting_info"
   },
   "outputs": [],
   "source": [
    "# Troubleshooting guide and diagnostics\n",
    "import torch\n",
    "import psutil\n",
    "import subprocess\n",
    "\n",
    "print(\"üîß Troubleshooting Guide\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "print(\"\\nüö® Common Issues and Solutions:\")\n",
    "print(\"\\n1. üí• GPU Out of Memory (OOM)\")\n",
    "print(\"   Solutions:\")\n",
    "print(\"   ‚Ä¢ Reduce batch_size from 48 to 32 or 16\")\n",
    "print(\"   ‚Ä¢ Use conservative mode: config['batch_size'] = 24\")\n",
    "print(\"   ‚Ä¢ Reduce memory_limit_gb from 14 to 12\")\n",
    "print(\"   ‚Ä¢ Ensure mixed precision is enabled (should be default)\")\n",
    "\n",
    "print(\"\\n2. üêå Slow Training Speed\")\n",
    "print(\"   Solutions:\")\n",
    "print(\"   ‚Ä¢ Verify T4 GPU is detected and optimizations enabled\")\n",
    "print(\"   ‚Ä¢ Check that cuDNN benchmark is enabled\")\n",
    "print(\"   ‚Ä¢ Reduce num_workers if data loading is bottleneck\")\n",
    "print(\"   ‚Ä¢ Use smaller, faster datasets for initial testing\")\n",
    "\n",
    "print(\"\\n3. üì∂ Colab Disconnection\")\n",
    "print(\"   Solutions:\")\n",
    "print(\"   ‚Ä¢ Training automatically saves every 2 epochs\")\n",
    "print(\"   ‚Ä¢ Models are backed up to Google Drive\")\n",
    "print(\"   ‚Ä¢ Re-run training cell to resume from last checkpoint\")\n",
    "print(\"   ‚Ä¢ Use Colab Pro for longer runtimes\")\n",
    "\n",
    "print(\"\\n4. üìö Dataset Loading Issues\")\n",
    "print(\"   Solutions:\")\n",
    "print(\"   ‚Ä¢ Try alternative datasets (see dataset section above)\")\n",
    "print(\"   ‚Ä¢ Check HuggingFace authentication token\")\n",
    "print(\"   ‚Ä¢ Verify internet connection stability\")\n",
    "print(\"   ‚Ä¢ Use smaller datasets for testing\")\n",
    "\n",
    "print(\"\\n5. üîë Authentication Problems\")\n",
    "print(\"   Solutions:\")\n",
    "print(\"   ‚Ä¢ Regenerate HuggingFace token if expired\")\n",
    "print(\"   ‚Ä¢ Check W&B API key validity\")\n",
    "print(\"   ‚Ä¢ Run authentication cells again\")\n",
    "print(\"   ‚Ä¢ Some datasets work without authentication\")\n",
    "\n",
    "# Current system diagnostics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üîç Current System Diagnostics:\")\n",
    "\n",
    "# GPU Status\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory_used = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "    gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"üéØ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ VRAM Usage: {gpu_memory_used:.1f}GB / {gpu_memory_total:.1f}GB\")\n",
    "    print(f\"‚ö° Mixed Precision Available: {torch.cuda.is_available()}\")\nelse:\n",
    "    print(f\"‚ùå No CUDA GPU available\")\n",
    "\n",
    "# System Memory\n",
    "ram_usage = psutil.virtual_memory()\n",
    "print(f\"üß† RAM Usage: {ram_usage.used/(1024**3):.1f}GB / {ram_usage.total/(1024**3):.1f}GB ({ram_usage.percent:.1f}%)\")\n",
    "\n",
    "# Disk Space\n",
    "disk_usage = psutil.disk_usage('/')\n",
    "print(f\"üíΩ Disk Usage: {disk_usage.used/(1024**3):.1f}GB / {disk_usage.total/(1024**3):.1f}GB ({disk_usage.used/disk_usage.total*100:.1f}%)\")\n",
    "\n",
    "# Environment Status\n",
    "print(f\"\\nüîß Environment:\")\n",
    "print(f\"   CUDA_LAUNCH_BLOCKING: {os.environ.get('CUDA_LAUNCH_BLOCKING', 'Not set')}\")\n",
    "print(f\"   CUDNN_BENCHMARK: {os.environ.get('CUDNN_BENCHMARK', 'Not set')}\")\n",
    "print(f\"   PYTORCH_CUDA_ALLOC_CONF: {os.environ.get('PYTORCH_CUDA_ALLOC_CONF', 'Not set')}\")\n",
    "\n",
    "print(f\"\\nüí° Quick Fixes:\")\n",
    "print(f\"   ‚Ä¢ Restart runtime if experiencing memory issues\")\n",
    "print(f\"   ‚Ä¢ Clear GPU memory: torch.cuda.empty_cache()\")\n",
    "print(f\"   ‚Ä¢ Check Google Drive storage space\")\n",
    "print(f\"   ‚Ä¢ Monitor training progress in W&B dashboard\")\n",
    "\n",
    "print(f\"\\nüìû Support Resources:\")\n",
    "print(f\"   ‚Ä¢ ImgAE-Dx GitHub Issues: [Repository URL]/issues\")\n",
    "print(f\"   ‚Ä¢ Google Colab Community: https://stackoverflow.com/questions/tagged/google-colaboratory\")\n",
    "print(f\"   ‚Ä¢ PyTorch Documentation: https://pytorch.org/docs/\")\n",
    "print(f\"   ‚Ä¢ HuggingFace Documentation: https://huggingface.co/docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "footer"
   },
   "source": [
    "---\n",
    "\n",
    "## üèÅ End of Notebook\n",
    "\n",
    "**ImgAE-Dx: Medical Image Anomaly Detection Framework**\n",
    "\n",
    "This notebook provided a complete workflow for training and evaluating autoencoder architectures for medical image anomaly detection on T4 GPU with the following features:\n",
    "\n",
    "‚úÖ **T4 GPU Optimization**: Mixed precision training with optimal batch sizes  \n",
    "‚úÖ **HuggingFace Integration**: Streaming datasets without local storage requirements  \n",
    "‚úÖ **Professional Checkpointing**: Automatic backup to Google Drive  \n",
    "‚úÖ **Experiment Tracking**: Weights & Biases integration  \n",
    "‚úÖ **Research Framework**: U-Net vs Reversed Autoencoder comparison  \n",
    "\n",
    "### üìä Expected Results\n",
    "- Training Speed: ~850 samples/sec (T4 + Mixed Precision)\n",
    "- Memory Efficiency: 75-85% T4 VRAM utilization\n",
    "- Research Quality: Publication-ready anomaly detection framework\n",
    "\n",
    "### üéØ Research Applications\n",
    "- Medical image anomaly detection\n",
    "- Unsupervised learning in healthcare\n",
    "- Architecture comparison studies\n",
    "- Large-scale medical dataset processing\n",
    "\n",
    "---\n",
    "\n",
    "**Developed with ‚ù§Ô∏è for the medical AI research community**\n",
    "\n",
    "*Based on: \"Towards Universal Unsupervised Anomaly Detection in Medical Imaging\"*\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}