{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImgAE-Dx Enhanced Training with Advanced Features\n",
    "\n",
    "This notebook implements research-grade training for medical image anomaly detection with:\n",
    "- Validation split and monitoring\n",
    "- Early stopping mechanism\n",
    "- Learning rate scheduling (Cosine Annealing)\n",
    "- Gradient clipping\n",
    "- Warmup epochs\n",
    "- Advanced checkpoint management\n",
    "\n",
    "## Quick Start:\n",
    "1. Set `CONFIG['model_type'] = 'both'` to train both U-Net and Reversed AE\n",
    "2. Run cells in order\n",
    "3. Monitor training progress with validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Colab Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU and mount Google Drive\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    gpu_info = !nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\n",
    "    print(f\"GPU: {gpu_info[0]}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected! Please enable GPU in Runtime > Change runtime type\")\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "print(\"‚úÖ Google Drive mounted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install ImgAE-Dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository if not exists\n",
    "if not os.path.exists('/content/ImgAE-Dx'):\n",
    "    !git clone https://github.com/kinhluan/ImgAE-Dx.git /content/ImgAE-Dx\n",
    "    %cd /content/ImgAE-Dx\n",
    "else:\n",
    "    %cd /content/ImgAE-Dx\n",
    "    !git pull\n",
    "\n",
    "# Add the src directory to Python path\n",
    "import sys\n",
    "if '/content/ImgAE-Dx/src' not in sys.path:\n",
    "    sys.path.append('/content/ImgAE-Dx/src')\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -e .\n",
    "!pip install datasets transformers accelerate\n",
    "!pip install wandb --upgrade\n",
    "\n",
    "print(\"‚úÖ ImgAE-Dx installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Enhanced Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research-grade T4-optimized configuration\n",
    "CONFIG = {\n",
    "    # Model settings\n",
    "    'model_type': 'both',  # 'unet', 'reversed_ae', or 'both'\n",
    "    \n",
    "    # Dataset source\n",
    "    'dataset_source': 'huggingface',\n",
    "    \n",
    "    # HuggingFace Dataset settings\n",
    "    'hf_dataset': 'hf-vision/chest-xray-pneumonia',\n",
    "    'hf_config': None,\n",
    "    'hf_split': 'train',\n",
    "    'hf_streaming': False,\n",
    "    'hf_token': None,\n",
    "    'image_column': 'image',\n",
    "    'label_column': 'labels',\n",
    "    \n",
    "    # Training settings (Research-optimized)\n",
    "    'samples': 8000,        # Increased for better generalization\n",
    "    'epochs': 50,           # Sufficient with early stopping\n",
    "    'batch_size': 32,       # Memory-safe for 2 models\n",
    "    'learning_rate': 5e-5,  # Stable medical image learning rate\n",
    "    'image_size': 128,\n",
    "    \n",
    "    # Advanced training features\n",
    "    'validation_split': 0.15,         # Monitor overfitting\n",
    "    'early_stopping_patience': 8,     # Prevent overtraining\n",
    "    'lr_scheduler': 'cosine',         # Better convergence\n",
    "    'gradient_clip_norm': 1.0,        # Training stability\n",
    "    'warmup_epochs': 3,               # Gradual learning rate warmup\n",
    "    'min_lr_factor': 0.1,             # Minimum LR as factor of initial LR\n",
    "    \n",
    "    # T4 optimizations\n",
    "    'mixed_precision': True,\n",
    "    'memory_limit': 13,      # Leave 3GB headroom\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'num_workers': 4,        # Increased for better data loading\n",
    "    \n",
    "    # Enhanced checkpointing\n",
    "    'checkpoint_dir': '/content/drive/MyDrive/imgae_dx_checkpoints',\n",
    "    'save_frequency': 5,\n",
    "    'keep_best_only': True,           # Save disk space\n",
    "    'resume_from_checkpoint': None,   # Path to resume from\n",
    "    'resume_model_type': None,        # Which model to resume\n",
    "    \n",
    "    # Logging\n",
    "    'use_wandb': False,\n",
    "    'wandb_project': 'imgae-dx-t4-colab',\n",
    "    'wandb_run_name': None,\n",
    "    'log_frequency': 1,              # Log every N batches\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(CONFIG['checkpoint_dir'], exist_ok=True)\n",
    "os.makedirs('/content/outputs/logs', exist_ok=True)\n",
    "os.makedirs('/content/outputs/plots', exist_ok=True)\n",
    "\n",
    "print(\"üöÄ Enhanced Configuration Set!\")\n",
    "print(f\"Model: {CONFIG['model_type']}\")\n",
    "print(f\"Samples: {CONFIG['samples']} (with {CONFIG['validation_split']:.1%} validation)\")\n",
    "print(f\"Epochs: {CONFIG['epochs']} (early stopping: {CONFIG['early_stopping_patience']})\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Learning rate: {CONFIG['learning_rate']} (scheduler: {CONFIG['lr_scheduler']})\")\n",
    "print(f\"Advanced features: Validation monitoring, Early stopping, LR scheduling, Gradient clipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup Weights & Biases (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG['use_wandb']:\n",
    "    import wandb\n",
    "    \n",
    "    wandb.login()\n",
    "    \n",
    "    run_name = CONFIG['wandb_run_name'] or f\"enhanced_{CONFIG['model_type']}_{CONFIG['samples']}samples\"\n",
    "    wandb.init(\n",
    "        project=CONFIG['wandb_project'],\n",
    "        name=run_name,\n",
    "        config=CONFIG\n",
    "    )\n",
    "    print(f\"‚úÖ W&B initialized: {run_name}\")\n",
    "else:\n",
    "    print(\"W&B logging disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Enhanced Dataset Loading with Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "print(f\"üìÇ Loading dataset: {CONFIG['hf_dataset']}...\")\n",
    "\n",
    "try:\n",
    "    # Authentication if needed\n",
    "    auth_kwargs = {'use_auth_token': CONFIG['hf_token']} if CONFIG['hf_token'] else {}\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = load_dataset(\n",
    "        CONFIG['hf_dataset'],\n",
    "        CONFIG['hf_config'],\n",
    "        split=CONFIG['hf_split'],\n",
    "        **auth_kwargs\n",
    "    )\n",
    "    \n",
    "    # Filter for NORMAL images only (label = 0)\n",
    "    # For unsupervised anomaly detection, we only train on normal images\n",
    "    normal_dataset = dataset.filter(lambda x: x[CONFIG['label_column']] == 0)\n",
    "    print(f\"üìä Filtered to {len(normal_dataset)} NORMAL images from {len(dataset)} total\")\n",
    "    \n",
    "    # Take specified number of samples\n",
    "    if len(normal_dataset) > CONFIG['samples']:\n",
    "        normal_dataset = normal_dataset.select(range(CONFIG['samples']))\n",
    "    \n",
    "    print(f\"‚úÖ Using {len(normal_dataset)} NORMAL images for training\")\n",
    "    print(f\"Dataset features: {normal_dataset.features}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "    raise\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Enhanced dataset wrapper\n",
    "class HFImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, transform):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        \n",
    "        # Get image\n",
    "        image = None\n",
    "        for col in [CONFIG['image_column'], 'image', 'img', 'pixel_values']:\n",
    "            if col in item:\n",
    "                image = item[col]\n",
    "                break\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(f\"No image column found. Available: {list(item.keys())}\")\n",
    "        \n",
    "        # Convert to PIL if needed\n",
    "        if not isinstance(image, Image.Image):\n",
    "            if isinstance(image, np.ndarray):\n",
    "                image = Image.fromarray(image)\n",
    "            else:\n",
    "                image = Image.fromarray(np.array(image))\n",
    "        \n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        return self.transform(image)\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = HFImageDataset(normal_dataset, transform)\n",
    "\n",
    "# Split into train and validation\n",
    "val_size = int(CONFIG['validation_split'] * len(full_dataset))\n",
    "train_size = len(full_dataset) - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # Reproducible split\n",
    ")\n",
    "\n",
    "print(f\"üìä Dataset split:\")\n",
    "print(f\"   Training: {len(train_dataset)} images\")\n",
    "print(f\"   Validation: {len(val_dataset)} images\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ DataLoaders created\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgae_dx.models import UNet, ReversedAutoencoder\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model initialization\n",
    "models_to_train = []\n",
    "\n",
    "if CONFIG['model_type'] in ['unet', 'both']:\n",
    "    unet = UNet(\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        features=[64, 128, 256, 512]\n",
    "    ).to(device)\n",
    "    models_to_train.append(('unet', unet))\n",
    "    print(\"‚úÖ U-Net initialized\")\n",
    "\n",
    "if CONFIG['model_type'] in ['reversed_ae', 'both']:\n",
    "    reversed_ae = ReversedAutoencoder(\n",
    "        in_channels=1,\n",
    "        latent_dim=128,\n",
    "        image_size=CONFIG['image_size']\n",
    "    ).to(device)\n",
    "    models_to_train.append(('reversed_ae', reversed_ae))\n",
    "    print(\"‚úÖ Reversed Autoencoder initialized\")\n",
    "\n",
    "# Count parameters\n",
    "print(\"\\nüìä Model Parameters:\")\n",
    "for name, model in models_to_train:\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"   {name}: {trainable_params:,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Enhanced Training with Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.utils as torch_utils\n",
    "\n",
    "# T4 optimizations\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.cuda.set_per_process_memory_fraction(CONFIG['memory_limit'] / 16.0)\n",
    "    print(f\"‚úÖ T4 optimizations enabled (Memory: {CONFIG['memory_limit']}GB)\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping utility class\"\"\"\n",
    "    def __init__(self, patience=8, min_delta=0.0001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        return self.early_stop\n",
    "\n",
    "def cosine_warmup_scheduler(optimizer, warmup_epochs, total_epochs, min_lr_factor=0.1):\n",
    "    \"\"\"Create cosine annealing scheduler with warmup\"\"\"\n",
    "    initial_lr = optimizer.param_groups[0]['lr']\n",
    "    min_lr = initial_lr * min_lr_factor\n",
    "    \n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < warmup_epochs:\n",
    "            # Warmup phase: linear increase from min_lr to initial_lr\n",
    "            return min_lr_factor + (1 - min_lr_factor) * epoch / warmup_epochs\n",
    "        else:\n",
    "            # Cosine annealing phase\n",
    "            progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
    "            return min_lr_factor + (1 - min_lr_factor) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate model on validation set\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images in val_loader:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            if CONFIG['mixed_precision']:\n",
    "                with autocast():\n",
    "                    reconstructed = model(images)\n",
    "                    loss = criterion(reconstructed, images)\n",
    "            else:\n",
    "                reconstructed = model(images)\n",
    "                loss = criterion(reconstructed, images)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_batches += 1\n",
    "    \n",
    "    return val_loss / val_batches if val_batches > 0 else float('inf')\n",
    "\n",
    "def enhanced_train_model(model_name, model, train_loader, val_loader, config):\n",
    "    \"\"\"Enhanced training function with all advanced features\"\"\"\n",
    "    print(f\"\\nüöÄ Enhanced Training: {model_name}\")\n",
    "    print(f\"   Features: Validation monitoring, Early stopping, LR scheduling, Gradient clipping\")\n",
    "    \n",
    "    # Setup optimizer and loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Mixed precision setup\n",
    "    scaler = GradScaler() if config['mixed_precision'] else None\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    if config['lr_scheduler'] == 'cosine':\n",
    "        scheduler = cosine_warmup_scheduler(\n",
    "            optimizer, \n",
    "            config['warmup_epochs'], \n",
    "            config['epochs'],\n",
    "            config['min_lr_factor']\n",
    "        )\n",
    "    else:\n",
    "        scheduler = None\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(patience=config['early_stopping_patience'])\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'learning_rate': []\n",
    "    }\n",
    "    \n",
    "    # Resume from checkpoint if specified\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    if (config.get('resume_from_checkpoint') and \n",
    "        config.get('resume_model_type') == model_name):\n",
    "        \n",
    "        print(f\"üìÇ Resuming {model_name} from checkpoint...\")\n",
    "        try:\n",
    "            checkpoint = torch.load(config['resume_from_checkpoint'], map_location=device)\n",
    "            \n",
    "            if 'model_state_dict' in checkpoint:\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                start_epoch = checkpoint['epoch']\n",
    "                best_val_loss = checkpoint.get('val_loss', float('inf'))\n",
    "                if 'history' in checkpoint:\n",
    "                    history = checkpoint['history']\n",
    "                print(f\"‚úÖ Resumed from epoch {start_epoch}, best val loss: {best_val_loss:.4f}\")\n",
    "            else:\n",
    "                model.load_state_dict(checkpoint)\n",
    "                print(f\"‚úÖ Loaded model weights, starting fresh training\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not resume: {e}. Starting fresh...\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(start_epoch, config['epochs']):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        # Get current learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['epochs']} [LR: {current_lr:.2e}]\")\n",
    "        \n",
    "        for batch_idx, images in enumerate(pbar):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            if config['mixed_precision']:\n",
    "                with autocast():\n",
    "                    reconstructed = model(images)\n",
    "                    loss = criterion(reconstructed, images)\n",
    "                \n",
    "                # Backward pass with gradient clipping\n",
    "                optimizer.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                if config.get('gradient_clip_norm'):\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch_utils.clip_grad_norm_(model.parameters(), config['gradient_clip_norm'])\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                reconstructed = model(images)\n",
    "                loss = criterion(reconstructed, images)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                \n",
    "                if config.get('gradient_clip_norm'):\n",
    "                    torch_utils.clip_grad_norm_(model.parameters(), config['gradient_clip_norm'])\n",
    "                \n",
    "                optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            train_loss += loss.item()\n",
    "            train_batches += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'avg_loss': f'{train_loss/train_batches:.4f}'\n",
    "            })\n",
    "            \n",
    "            # Log to W&B\n",
    "            if config['use_wandb'] and batch_idx % config.get('log_frequency', 10) == 0:\n",
    "                wandb.log({\n",
    "                    f'{model_name}_batch_loss': loss.item(),\n",
    "                    f'{model_name}_learning_rate': current_lr,\n",
    "                    'epoch': epoch,\n",
    "                    'batch': batch_idx\n",
    "                })\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        avg_train_loss = train_loss / train_batches\n",
    "        \n",
    "        # Validation phase\n",
    "        avg_val_loss = validate_model(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['learning_rate'].append(current_lr)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}, LR = {current_lr:.2e}\")\n",
    "        \n",
    "        # Log epoch metrics\n",
    "        if config['use_wandb']:\n",
    "            wandb.log({\n",
    "                f'{model_name}_train_loss': avg_train_loss,\n",
    "                f'{model_name}_val_loss': avg_val_loss,\n",
    "                f'{model_name}_learning_rate': current_lr,\n",
    "                'epoch': epoch + 1\n",
    "            })\n",
    "        \n",
    "        # Update learning rate\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Save checkpoint\n",
    "        save_checkpoint = False\n",
    "        \n",
    "        if (epoch + 1) % config['save_frequency'] == 0:\n",
    "            save_checkpoint = True\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_checkpoint = True\n",
    "            \n",
    "            # Save best model\n",
    "            best_path = f\"{config['checkpoint_dir']}/{model_name}_best.pth\"\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f\"‚úÖ Best model saved: {best_path} (Val Loss: {best_val_loss:.4f})\")\n",
    "        \n",
    "        if save_checkpoint and not config.get('keep_best_only', False):\n",
    "            checkpoint_path = f\"{config['checkpoint_dir']}/{model_name}_epoch_{epoch+1}.pth\"\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'history': history,\n",
    "                'config': config\n",
    "            }, checkpoint_path)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stopping(avg_val_loss):\n",
    "            print(f\"üõë Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Train models\n",
    "all_histories = {}\n",
    "trained_models = {}\n",
    "\n",
    "print(f\"üöÄ Starting enhanced training for {len(models_to_train)} model(s)...\")\n",
    "\n",
    "for model_name, model in models_to_train:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Enhanced training\n",
    "    trained_model, history = enhanced_train_model(\n",
    "        model_name, model, train_loader, val_loader, CONFIG\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    trained_models[model_name] = trained_model\n",
    "    all_histories[model_name] = history\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = (time.time() - start_time) / 60\n",
    "    print(f\"\\n‚úÖ {model_name} enhanced training completed in {training_time:.1f} minutes\")\n",
    "    \n",
    "    # Clear cache between models\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nüéâ All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Enhanced Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced training visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Training and Validation Loss\n",
    "for model_name, history in all_histories.items():\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    axes[0, 0].plot(epochs, history['train_loss'], label=f'{model_name} train', linestyle='-')\n",
    "    axes[0, 0].plot(epochs, history['val_loss'], label=f'{model_name} val', linestyle='--')\n",
    "\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss (MSE)')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Learning Rate Schedule\n",
    "for model_name, history in all_histories.items():\n",
    "    epochs = range(1, len(history['learning_rate']) + 1)\n",
    "    axes[0, 1].plot(epochs, history['learning_rate'], label=f'{model_name} LR')\n",
    "\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Learning Rate')\n",
    "axes[0, 1].set_title('Learning Rate Schedule')\n",
    "axes[0, 1].set_yscale('log')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Validation Loss Improvement\n",
    "for model_name, history in all_histories.items():\n",
    "    val_losses = history['val_loss']\n",
    "    best_val_loss = [min(val_losses[:i+1]) for i in range(len(val_losses))]\n",
    "    epochs = range(1, len(best_val_loss) + 1)\n",
    "    axes[1, 0].plot(epochs, best_val_loss, label=f'{model_name} best val')\n",
    "\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Best Validation Loss')\n",
    "axes[1, 0].set_title('Best Validation Loss Progress')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Train vs Val Loss Correlation\n",
    "for model_name, history in all_histories.items():\n",
    "    axes[1, 1].scatter(history['train_loss'], history['val_loss'], \n",
    "                      label=f'{model_name}', alpha=0.7, s=30)\n",
    "\n",
    "# Add diagonal line\n",
    "min_loss = min([min(h['train_loss'] + h['val_loss']) for h in all_histories.values()])\n",
    "max_loss = max([max(h['train_loss'] + h['val_loss']) for h in all_histories.values()])\n",
    "axes[1, 1].plot([min_loss, max_loss], [min_loss, max_loss], 'k--', alpha=0.5, label='Perfect correlation')\n",
    "\n",
    "axes[1, 1].set_xlabel('Training Loss')\n",
    "axes[1, 1].set_ylabel('Validation Loss')\n",
    "axes[1, 1].set_title('Training vs Validation Loss Correlation')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Enhanced Training Analysis', fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save enhanced plots\n",
    "plt.savefig(f'{CONFIG[\"checkpoint_dir\"]}/enhanced_training_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Enhanced training analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Reconstruction Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_enhanced_reconstructions(models, train_loader, val_loader, num_samples=5):\n",
    "    \"\"\"Enhanced reconstruction visualization with train and validation samples\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(len(models) + 1, num_samples * 2, figsize=(20, 3 * (len(models) + 1)))\n",
    "    \n",
    "    # Get samples from both train and validation\n",
    "    train_batch = next(iter(train_loader))[:num_samples].to(device)\n",
    "    val_batch = next(iter(val_loader))[:num_samples].to(device)\n",
    "    \n",
    "    sample_batches = [train_batch, val_batch]\n",
    "    batch_labels = ['Train', 'Validation']\n",
    "    \n",
    "    # Original images\n",
    "    for batch_idx, (batch, label) in enumerate(zip(sample_batches, batch_labels)):\n",
    "        for i in range(num_samples):\n",
    "            col_idx = batch_idx * num_samples + i\n",
    "            img = batch[i].cpu().squeeze().numpy()\n",
    "            axes[0, col_idx].imshow(img, cmap='gray', vmin=-1, vmax=1)\n",
    "            axes[0, col_idx].axis('off')\n",
    "            if col_idx == 0:\n",
    "                axes[0, col_idx].set_ylabel('Original', fontsize=12)\n",
    "            if batch_idx == 0 and i == num_samples // 2:\n",
    "                axes[0, col_idx].set_title('Training Samples', fontsize=10)\n",
    "            elif batch_idx == 1 and i == num_samples // 2:\n",
    "                axes[0, col_idx].set_title('Validation Samples', fontsize=10)\n",
    "    \n",
    "    # Reconstructions for each model\n",
    "    for model_idx, (model_name, model) in enumerate(models.items()):\n",
    "        model.eval()\n",
    "        \n",
    "        for batch_idx, batch in enumerate(sample_batches):\n",
    "            with torch.no_grad():\n",
    "                recon = model(batch)\n",
    "            \n",
    "            for i in range(num_samples):\n",
    "                col_idx = batch_idx * num_samples + i\n",
    "                img = recon[i].cpu().squeeze().numpy()\n",
    "                axes[model_idx + 1, col_idx].imshow(img, cmap='gray', vmin=-1, vmax=1)\n",
    "                axes[model_idx + 1, col_idx].axis('off')\n",
    "                \n",
    "                if col_idx == 0:\n",
    "                    axes[model_idx + 1, col_idx].set_ylabel(model_name, fontsize=12)\n",
    "    \n",
    "    plt.suptitle('Enhanced Reconstruction Quality Assessment', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(f'{CONFIG[\"checkpoint_dir\"]}/enhanced_reconstruction_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Enhanced reconstruction comparison saved\")\n",
    "\n",
    "# Visualize enhanced reconstructions\n",
    "if trained_models:\n",
    "    visualize_enhanced_reconstructions(trained_models, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Enhanced Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Enhanced summary with validation metrics\n",
    "summary = {\n",
    "    'metadata': {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'notebook_version': 'enhanced_training',\n",
    "        'dataset': CONFIG['hf_dataset'],\n",
    "        'total_samples': CONFIG['samples'],\n",
    "        'train_samples': len(train_dataset),\n",
    "        'val_samples': len(val_dataset),\n",
    "        'validation_split': CONFIG['validation_split']\n",
    "    },\n",
    "    'config': CONFIG,\n",
    "    'training_results': {},\n",
    "    'advanced_features_used': [\n",
    "        'validation_monitoring',\n",
    "        'early_stopping',\n",
    "        'cosine_lr_scheduling',\n",
    "        'gradient_clipping',\n",
    "        'warmup_epochs',\n",
    "        'mixed_precision'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Calculate detailed metrics for each model\n",
    "for model_name, history in all_histories.items():\n",
    "    train_losses = history['train_loss']\n",
    "    val_losses = history['val_loss']\n",
    "    learning_rates = history['learning_rate']\n",
    "    \n",
    "    summary['training_results'][model_name] = {\n",
    "        'epochs_trained': len(train_losses),\n",
    "        'final_train_loss': train_losses[-1],\n",
    "        'final_val_loss': val_losses[-1],\n",
    "        'best_train_loss': min(train_losses),\n",
    "        'best_val_loss': min(val_losses),\n",
    "        'best_val_epoch': val_losses.index(min(val_losses)) + 1,\n",
    "        'final_learning_rate': learning_rates[-1],\n",
    "        'convergence_achieved': val_losses[-1] < 0.05,  # Threshold for good convergence\n",
    "        'overfitting_detected': train_losses[-1] < val_losses[-1] * 0.5,  # Rough heuristic\n",
    "        'training_stability': max(train_losses) / min(train_losses),  # Lower is more stable\n",
    "    }\n",
    "\n",
    "# Save enhanced summary\n",
    "summary_path = f\"{CONFIG['checkpoint_dir']}/enhanced_training_summary.json\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# Print comprehensive summary\n",
    "print(\"\\nüéØ ENHANCED TRAINING SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"üìä Dataset: {CONFIG['hf_dataset']}\")\n",
    "print(f\"üìà Samples: {CONFIG['samples']} ({len(train_dataset)} train + {len(val_dataset)} val)\")\n",
    "print(f\"üîß Advanced Features: {', '.join(summary['advanced_features_used'])}\")\n",
    "\n",
    "for model_name, results in summary['training_results'].items():\n",
    "    print(f\"\\nü§ñ {model_name.upper()} RESULTS:\")\n",
    "    print(f\"   Epochs Trained: {results['epochs_trained']}\")\n",
    "    print(f\"   Final Train Loss: {results['final_train_loss']:.4f}\")\n",
    "    print(f\"   Final Val Loss: {results['final_val_loss']:.4f}\")\n",
    "    print(f\"   Best Val Loss: {results['best_val_loss']:.4f} (Epoch {results['best_val_epoch']})\")\n",
    "    print(f\"   Final Learning Rate: {results['final_learning_rate']:.2e}\")\n",
    "    print(f\"   Convergence: {'‚úÖ' if results['convergence_achieved'] else '‚ö†Ô∏è'} {'Good' if results['convergence_achieved'] else 'Needs improvement'}\")\n",
    "    print(f\"   Overfitting: {'‚ö†Ô∏è' if results['overfitting_detected'] else '‚úÖ'} {'Detected' if results['overfitting_detected'] else 'Not detected'}\")\n",
    "    print(f\"   Training Stability: {results['training_stability']:.2f}x (lower is better)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Enhanced summary saved to: {summary_path}\")\n",
    "print(f\"üìÅ All checkpoints and artifacts saved to: {CONFIG['checkpoint_dir']}\")\n",
    "\n",
    "# Finish W&B run\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.finish()\n",
    "    print(\"‚úÖ W&B run finished\")\n",
    "\n",
    "print(\"\\nüéâ ENHANCED TRAINING COMPLETE! Ready for evaluation phase.\")\n",
    "print(\"üí° Next step: Use evaluation cells 21-26 from EVALUATION_GUIDE.md to answer research questions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
