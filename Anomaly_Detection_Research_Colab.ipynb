{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dự Án Nghiên Cứu: Phát Hiện Bất Thường Ảnh Y Khoa\n",
    "### So sánh hiệu suất giữa U-Net (Baseline) và Reversed Autoencoder (Thử nghiệm)\n",
    "*Notebook được cấu trúc theo từng phần, hãy chạy lần lượt từ trên xuống dưới.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 0: Thiết Lập Môi Trường & Dữ Liệu\n",
    "**Mô tả:** Phần này thực hiện các thao tác cài đặt ban đầu, chỉ cần chạy một lần duy nhất khi bắt đầu phiên làm việc.\n",
    "\n",
    "**Hướng dẫn:**\n",
    "1.  Chạy ô code đầu tiên để kết nối Google Drive. **Đây là bước bắt buộc để lưu checkpoint.**\n",
    "2.  Chạy ô code thứ hai để cài đặt các thư viện cần thiết.\n",
    "3.  Chạy ô code thứ ba để tải lên file `kaggle.json` của bạn. Bạn có thể lấy file này từ trang tài khoản Kaggle.\n",
    "4.  Chạy ô code thứ tư để tải và giải nén dữ liệu. Quá trình này có thể mất vài phút."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Kết nối Google Drive để lưu trữ bền vững (checkpoint, model)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cài đặt các thư viện cần thiết\n",
    "!pip install -q pandas scikit-learn matplotlib torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tải lên file kaggle.json để xác thực\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
    "    print(\"Vui lòng upload file kaggle.json của bạn.\")\n",
    "    files.upload()\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "print(\"Thiết lập Kaggle API thành công!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tải và giải nén dữ liệu từ Kaggle\n",
    "print(\"Bắt đầu tải dữ liệu...\")\n",
    "!kaggle datasets download -d nih-chest-xray/data -f Data_Entry_BBOX.csv -q\n",
    "!kaggle datasets download -d nih-chest-xray/data -f images_001.zip -q\n",
    "!kaggle datasets download -d nih-chest-xray/data -f images_002.zip -q\n",
    "\n",
    "print(\"Bắt đầu giải nén...\")\n",
    "!unzip -q Data_Entry_BBOX.csv.zip -d .\n",
    "!unzip -q images_001.zip -d .\n",
    "!unzip -q images_002.zip -d .\n",
    "print(\"Hoàn tất chuẩn bị dữ liệu!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 1: Cấu Hình Toàn Cục\n",
    "**Mô tả:** Ô code dưới đây chứa tất cả các tham số và biến cấu hình cho dự án. Việc tập trung chúng vào một nơi giúp dễ dàng theo dõi và thay đổi khi cần thử nghiệm.\n",
    "\n",
    "**Hướng dẫn:** Chạy ô này để khởi tạo các biến. Bạn có thể quay lại đây để thay đổi các giá trị như `EPOCHS` hoặc `LEARNING_RATE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# --- Cấu hình cho dự án ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMAGE_DIR = \"/content/images\"\n",
    "METADATA_PATH = \"/content/Data_Entry_BBOX.csv\"\n",
    "\n",
    "# --- Cấu hình Checkpoint & Lưu trữ Model ---\n",
    "# Thư mục để lưu model tốt nhất\n",
    "SAVE_MODEL_DIR = \"/content/drive/MyDrive/Xray_Anomaly/saved_models\"\n",
    "# Thư mục để lưu checkpoint trên Google Drive của bạn\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/Xray_Anomaly/checkpoints'\n",
    "os.makedirs(SAVE_MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Giảm số lượng dữ liệu để chạy demo nhanh hơn\n",
    "NUM_NORMAL_SAMPLES = 2500\n",
    "NUM_ABNORMAL_SAMPLES = 1200\n",
    "\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20 # Tăng lên để có kết quả tốt hơn\n",
    "LR = 1e-4\n",
    "\n",
    "print(f\"Thiết bị đang sử dụng: {DEVICE}\")\n",
    "print(f\"Thư mục lưu model tốt nhất: {SAVE_MODEL_DIR}\")\n",
    "print(f\"Thư mục lưu checkpoint: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 2: Định Nghĩa Các Mô Hình\n",
    "**Mô tả:** Ô code này chứa định nghĩa kiến trúc cho cả hai mô hình: U-Net (baseline) và Reversed Autoencoder (thử nghiệm).\n",
    "\n",
    "**Hướng dẫn:** Chạy ô này để khai báo các lớp (class) mô hình. Sau khi chạy, bạn có thể thu gọn ô này lại cho gọn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "# --- 2A. Mô Hình Baseline: U-Net ---\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.enc1 = self.conv_block(1, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.bottleneck = self.conv_block(256, 512)\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool(e1)\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool(e2)\n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool(e3)\n",
    "        b = self.bottleneck(p3)\n",
    "        d3 = self.upconv3(b)\n",
    "        d3 = torch.cat((e3, d3), dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat((e2, d2), dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat((e1, d1), dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        output = self.tanh(self.out_conv(d1))\n",
    "        return output\n",
    "\n",
    "# --- 2B. Mô Hình Thử Nghiệm: Reversed Autoencoder (RA) ---\n",
    "class ReversedAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReversedAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1), nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 7))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 7), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "print(\"Đã khai báo xong các lớp Model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 3: Logic Xử Lý Dữ Liệu\n",
    "**Mô tả:** Ô code này chứa logic để đọc metadata, phân chia dữ liệu và tạo ra các `DataLoader` để cung cấp dữ liệu cho mô hình trong quá trình huấn luyện và đánh giá.\n",
    "\n",
    "**Hướng dẫn:** Chạy ô này để chuẩn bị sẵn sàng các bộ dữ liệu. Sau khi chạy, bạn có thể thu gọn ô này lại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def get_data_loaders():\n",
    "    df = pd.read_csv(METADATA_PATH)\n",
    "    all_image_paths = glob.glob(os.path.join(IMAGE_DIR, '*.png'))\n",
    "    image_filenames = {os.path.basename(p): p for p in all_image_paths}\n",
    "    df['full_path'] = df['Image Index'].map(image_filenames)\n",
    "    df = df.dropna(subset=['full_path'])\n",
    "\n",
    "    normal_df = df[df['Finding Labels'] == 'No Finding'].sample(n=NUM_NORMAL_SAMPLES, random_state=42)\n",
    "    abnormal_df = df[df['Finding Labels'] != 'No Finding'].sample(n=NUM_ABNORMAL_SAMPLES, random_state=42)\n",
    "\n",
    "    train_df, val_df = train_test_split(normal_df, test_size=0.2, random_state=42)\n",
    "    test_normal_df = val_df.sample(n=int(len(val_df)*0.5), random_state=42)\n",
    "    test_df = pd.concat([test_normal_df, abnormal_df])\n",
    "\n",
    "    class ChestXrayDataset(Dataset):\n",
    "        def __init__(self, dataframe, transform):\n",
    "            self.dataframe = dataframe\n",
    "            self.transform = transform\n",
    "        def __len__(self): return len(self.dataframe)\n",
    "        def __getitem__(self, idx):\n",
    "            row = self.dataframe.iloc[idx]\n",
    "            image = Image.open(row['full_path']).convert(\"L\")\n",
    "            label = 0 if row['Finding Labels'] == 'No Finding' else 1\n",
    "            return self.transform(image), label\n",
    "\n",
    "    transform_set = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "    train_loader = DataLoader(ChestXrayDataset(train_df, transform_set), batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(ChestXrayDataset(val_df, transform_set), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(ChestXrayDataset(test_df, transform_set), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    print(f\"Đã tạo xong DataLoaders: Train={len(train_loader.dataset)}, Val={len(val_loader.dataset)}, Test={len(test_loader.dataset)}\")\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = get_data_loaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 4: Logic Huấn Luyện (Có Checkpointing)\n",
    "**Mô tả:** Ô code này định nghĩa hàm `train_model_with_checkpointing`, chứa logic huấn luyện có thể tái sử dụng cho bất kỳ mô hình nào. **Điểm nâng cấp quan trọng:** hàm này có khả năng tự động lưu và tải lại tiến trình từ Google Drive.\n",
    "\n",
    "**Hướng dẫn:** Chạy ô này để khai báo hàm. Sau đó, bạn có thể thu gọn nó lại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model_with_checkpointing(model, model_name, train_loader, val_loader):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f'{model_name}_checkpoint.pth')\n",
    "    \n",
    "    start_epoch = 0\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # --- LOGIC TẢI CHECKPOINT ---\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Tìm thấy checkpoint! Đang tải từ: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        history = checkpoint['history']\n",
    "        best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "        print(f\"==> Tiếp tục huấn luyện từ Epoch {start_epoch + 1} <==\")\n",
    "    else:\n",
    "        print(f\"Không tìm thấy checkpoint cho {model_name}. Bắt đầu huấn luyện từ đầu.\")\n",
    "\n",
    "    # --- VÒNG LẶP HUẤN LUYỆN ---\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for images, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "            images = images.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, _ in val_loader:\n",
    "                images = images.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, images)\n",
    "                running_val_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - {model_name} - Train Loss: {epoch_train_loss:.6f}, Val Loss: {epoch_val_loss:.6f}\")\n",
    "        \n",
    "        # --- LOGIC LƯU CHECKPOINT ---\n",
    "        # Lưu model tốt nhất dựa trên val loss\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_model_path = os.path.join(SAVE_MODEL_DIR, f'{model_name}_best.pth')\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Validation loss cải thiện. Lưu model tốt nhất tại: {best_model_path}\")\n",
    "\n",
    "        # Luôn lưu checkpoint của epoch cuối cùng để có thể resume\n",
    "        torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'history': history,\n                'best_val_loss': best_val_loss\n            }, checkpoint_path)\n            \n",
    "    print(f\"Hoàn tất huấn luyện {model_name}\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 5: Thực Thi Huấn Luyện\n",
    "**Mô tả:** Đây là khu vực thực thi chính. Các ô code dưới đây sẽ khởi tạo và huấn luyện lần lượt từng mô hình. Nếu bạn chạy lại các ô này sau khi bị ngắt kết nối, chúng sẽ tự động tìm và tải checkpoint từ Google Drive.\n",
    "\n",
    "**Hướng dẫn:** Chạy lần lượt các ô để huấn luyện U-Net, sau đó đến Reversed Autoencoder, và cuối cùng là vẽ đồ thị loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5a. Huấn luyện mô hình U-Net\n",
    "print(\"--- Bắt đầu quy trình huấn luyện U-Net Baseline ---\")\n",
    "unet_model = UNet().to(DEVICE)\n",
    "unet_model, unet_history = train_model_with_checkpointing(unet_model, \"unet\", train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n--- Bắt đầu quy trình huấn luyện Reversed Autoencoder ---\")\n",
    "ra_model = ReversedAutoencoder().to(DEVICE)\n",
    "ra_model, ra_history = train_model_with_checkpointing(ra_model, \"ra\", train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5c. Vẽ đồ thị loss để so sánh quá trình học\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(unet_history['train_loss'], label='U-Net Train Loss')\n",
    "plt.plot(unet_history['val_loss'], label='U-Net Val Loss')\n",
    "plt.title('U-Net Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(ra_history['train_loss'], label='RA Train Loss')\n",
    "plt.plot(ra_history['val_loss'], label='RA Val Loss')\n",
    "plt.title('Reversed Autoencoder Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 6: Đánh Giá & Báo Cáo Kết Quả\n",
    "**Mô tả:** Sau khi các mô hình đã được huấn luyện, phần này sẽ tải lại phiên bản tốt nhất của chúng (file `..._best.pth`) và thực hiện tất cả các phân tích so sánh.\n",
    "\n",
    "**Hướng dẫn:** Chạy các ô bên dưới để tính toán các chỉ số, vẽ biểu đồ và hiển thị các hình ảnh so sánh trực quan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6a. Định nghĩa các hàm hỗ trợ đánh giá\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model_performance(model, data_loader):\n",
    "    model.eval()\n",
    "    reconstruction_errors = []\n",
    "    true_labels = []\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            error = criterion(outputs, images).mean(dim=[1, 2, 3])\n",
    "            reconstruction_errors.extend(error.cpu().numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "    return np.array(reconstruction_errors), np.array(true_labels)\n",
    "\n",
    "def visualize_comparison(model1, model2, model1_name, model2_name, data_loader, num_images=5):\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    images, labels = next(iter(data_loader))\n",
    "    images = images.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs1 = model1(images).cpu()\n",
    "        outputs2 = model2(images).cpu()\n",
    "        error_map1 = torch.mean(nn.functional.mse_loss(outputs1, images.cpu(), reduction='none'), dim=1)\n",
    "        error_map2 = torch.mean(nn.functional.mse_loss(outputs2, images.cpu(), reduction='none'), dim=1)\n",
    "    \n",
    "    plt.figure(figsize=(25, num_images * 5))\n",
    "    for i in range(num_images):\n",
    "        label_text = \"Abnormal\" if labels[i] == 1 else \"Normal\"\n",
    "        img_display = images[i].cpu() * 0.5 + 0.5\n",
    "        recon1_display = outputs1[i] * 0.5 + 0.5\n",
    "        recon2_display = outputs2[i] * 0.5 + 0.5\n",
    "        \n",
    "        plt.subplot(num_images, 5, i * 5 + 1); plt.imshow(img_display.squeeze(), cmap='gray'); plt.title(f\"Original ({label_text})\"); plt.axis('off')\n",
    "        plt.subplot(num_images, 5, i * 5 + 2); plt.imshow(recon1_display.squeeze(), cmap='gray'); plt.title(f\"{model1_name} Recon\"); plt.axis('off')\n",
    "        plt.subplot(num_images, 5, i * 5 + 3); plt.imshow(error_map1[i], cmap='jet'); plt.title(f\"{model1_name} Error Map\"); plt.axis('off')\n",
    "        plt.subplot(num_images, 5, i * 5 + 4); plt.imshow(recon2_display.squeeze(), cmap='gray'); plt.title(f\"{model2_name} Recon\"); plt.axis('off')\n",
    "        plt.subplot(num_images, 5, i * 5 + 5); plt.imshow(error_map2[i], cmap='jet'); plt.title(f\"{model2_name} Error Map\"); plt.axis('off')\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6b. Chạy đánh giá và tính toán chỉ số\n",
    "# Tải lại các model tốt nhất đã được lưu trong quá trình training\n",
    "unet_eval = UNet().to(DEVICE)\n",
    "unet_eval.load_state_dict(torch.load(os.path.join(SAVE_MODEL_DIR, 'unet_best.pth')))\n",
    "\n",
    "ra_eval = ReversedAutoencoder().to(DEVICE)\n",
    "ra_eval.load_state_dict(torch.load(os.path.join(SAVE_MODEL_DIR, 'ra_best.pth')))\n",
    "\n",
    "print(\"Bắt đầu đánh giá U-Net...\")\n",
    "unet_errors, unet_labels = evaluate_model_performance(unet_eval, test_loader)\n",
    "unet_auc = roc_auc_score(unet_labels, unet_errors)\n",
    "\n",
    "print(\"Bắt đầu đánh giá Reversed Autoencoder...\")\n",
    "ra_errors, ra_labels = evaluate_model_performance(ra_eval, test_loader)\n",
    "ra_auc = roc_auc_score(ra_labels, ra_errors)\n",
    "\n",
    "print(\"--- KẾT QUẢ ĐÁNH GIÁ ---\")\n",
    "print(f\"AUC của U-Net: {unet_auc:.4f}\")\n",
    "print(f\"AUC của Reversed Autoencoder: {ra_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6c. Trực quan hóa kết quả so sánh\n",
    "# Vẽ đường cong ROC\n",
    "unet_fpr, unet_tpr, _ = roc_curve(unet_labels, unet_errors)\n",
    "ra_fpr, ra_tpr, _ = roc_curve(ra_labels, ra_errors)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(unet_fpr, unet_tpr, label=f'U-Net (AUC = {unet_auc:.4f})', linewidth=2)\n",
    "plt.plot(ra_fpr, ra_tpr, label=f'Reversed Autoencoder (AUC = {ra_auc:.4f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('So Sánh Đường Cong ROC', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Trực quan hóa hình ảnh so sánh\n",
    "print(\"\n--- So Sánh Trực Quan Trên Ảnh Test ---\")\n",
    "visualize_comparison(unet_eval, ra_eval, \"U-Net\", \"RA\", test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 7: Kết Luận Cuối Cùng\n",
    "**Mô tả:** Đây là phần cuối cùng, nơi bạn sẽ viết ra những phân tích và kết luận của mình dựa trên các kết quả đã được tạo ra ở trên.\n",
    "\n",
    "**Hướng dẫn:** Dựa vào điểm AUC và các hình ảnh so sánh, hãy trả lời các câu hỏi sau:\n",
    "1.  **Mô hình nào hoạt động hiệu quả hơn?** \n",
    "    *Phân tích của bạn ở đây. Ví dụ: Dựa trên kết quả, mô hình U-Net với AUC là [điền số] đã cho thấy hiệu suất vượt trội so với Reversed Autoencoder (AUC = [điền số])...*\n",
    "\n",
    "2.  **Tại sao mô hình đó lại hiệu quả hơn (dựa trên hình ảnh)?** \n",
    "    *Phân tích của bạn ở đây. Ví dụ: Khi quan sát các bản đồ lỗi, có thể thấy U-Net tạo ra các vùng lỗi tập trung và rõ nét hơn tại vị trí bất thường. Điều này có thể là do các kết nối tắt (skip connections) đã giúp U-Net tái tạo nền (background) của ảnh tốt hơn, từ đó làm nổi bật sự khác biệt do bệnh lý gây ra...*\n",
    "\n",
    "3.  **Hạn chế của nghiên cứu này là gì?** \n",
    "    *Phân tích của bạn ở đây. Ví dụ: Nghiên cứu được thực hiện trên một tập dữ liệu con và với số epoch giới hạn. Kết quả có thể được cải thiện hơn nữa nếu huấn luyện trên toàn bộ dữ liệu với thời gian dài hơn...*\n",
    "\n",
    "4.  **Hướng phát triển tiếp theo là gì?** \n",
    "    *Phân tích của bạn ở đây. Ví dụ: Các bước tiếp theo có thể bao gồm việc tinh chỉnh siêu tham số cho mô hình chiến thắng, thử nghiệm với các hàm loss khác nhau (như SSIM), và áp dụng mô hình lên các bộ dữ liệu khác (như MURA hoặc MRI) để kiểm tra khả năng tổng quát hóa...*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dự Án Nghiên Cứu: Phát Hiện Bất Thường Ảnh Y Khoa\n",
    "### So sánh hiệu suất giữa U-Net (Baseline) và Reversed Autoencoder (Thử nghiệm)\n",
    "*Notebook được cấu trúc theo từng phần, hãy chạy lần lượt từ trên xuống dưới.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 0: Thiết Lập Môi Trường & Dữ Liệu\n",
    "**Mô tả:** Phần này thực hiện các thao tác cài đặt ban đầu, chỉ cần chạy một lần duy nhất khi bắt đầu phiên làm việc.\n",
    "\n",
    "**Hướng dẫn:**\n",
    "1.  Chạy ô code đầu tiên để cài đặt các thư viện cần thiết.\n",
    "2.  Chạy ô code thứ hai để tải lên file `kaggle.json` của bạn. Bạn có thể lấy file này từ trang tài khoản Kaggle.\n",
    "3.  Chạy ô code thứ ba để tải và giải nén dữ liệu. Quá trình này có thể mất vài phút."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cài đặt các thư viện cần thiết\n",
    "!pip install -q pandas scikit-learn matplotlib torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tải lên file kaggle.json để xác thực\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
    "    print(\"Vui lòng upload file kaggle.json của bạn.\")\n",
    "    # Dòng code này sẽ mở ra một nút để bạn chọn file từ máy tính.\n",
    "    files.upload()\n",
    "\n",
    "# Tạo thư mục và cấp quyền cho file kaggle.json\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "print(\"Thiết lập Kaggle API thành công!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tải và giải nén dữ liệu từ Kaggle\n",
    "print(\"Bắt đầu tải dữ liệu...\")\n",
    "# Chỉ tải file metadata và 2 file ảnh zip nhỏ để demo\n",
    "!kaggle datasets download -d nih-chest-xray/data -f Data_Entry_BBOX.csv -q\n",
    "!kaggle datasets download -d nih-chest-xray/data -f images_001.zip -q\n",
    "!kaggle datasets download -d nih-chest-xray/data -f images_002.zip -q\n",
    "\n",
    "print(\"Bắt đầu giải nén...\")\n",
    "!unzip -q Data_Entry_BBOX.csv.zip -d .\n",
    "!unzip -q images_001.zip -d .\n",
    "!unzip -q images_002.zip -d .\n",
    "print(\"Hoàn tất chuẩn bị dữ liệu!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 1: Cấu Hình Toàn Cục\n",
    "**Mô tả:** Ô code dưới đây chứa tất cả các tham số và biến cấu hình cho dự án. Việc tập trung chúng vào một nơi giúp dễ dàng theo dõi và thay đổi khi cần thử nghiệm.\n",
    "\n",
    "**Hướng dẫn:** Chạy ô này để khởi tạo các biến. Bạn có thể quay lại đây để thay đổi các giá trị như `EPOCHS` hoặc `LEARNING_RATE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# --- Cấu hình cho dự án ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMAGE_DIR = \"/content/images\"\n",
    "METADATA_PATH = \"/content/Data_Entry_BBOX.csv\"\n",
    "SAVE_MODEL_DIR = \"/content/saved_models\"\n",
    "os.makedirs(SAVE_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Giảm số lượng dữ liệu để chạy demo nhanh hơn\n",
    "NUM_NORMAL_SAMPLES = 2500  # Tăng lên để có kết quả tốt hơn\n",
    "NUM_ABNORMAL_SAMPLES = 1200 # Tăng lên để có kết quả tốt hơn\n",
    "\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15 # Tăng lên 25-30 cho kết quả tốt hơn\n",
    "LR = 1e-4\n",
    "\n",
    "print(f\"Thiết bị đang sử dụng: {DEVICE}\")\n",
    "print(f\"Thư mục lưu model: {SAVE_MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 2: Định Nghĩa Các Mô Hình\n",
    "**Mô tả:** Ô code này chứa định nghĩa kiến trúc cho cả hai mô hình: U-Net (baseline) và Reversed Autoencoder (thử nghiệm).\n",
    "\n",
    "**Hướng dẫn:** Chạy ô này để khai báo các lớp (class) mô hình. Sau khi chạy, bạn có thể thu gọn ô này lại cho gọn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "# --- 2A. Mô Hình Baseline: U-Net ---\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.enc1 = self.conv_block(1, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.bottleneck = self.conv_block(256, 512)\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool(e1)\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool(e2)\n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool(e3)\n",
    "        b = self.bottleneck(p3)\n",
    "        d3 = self.upconv3(b)\n",
    "        d3 = torch.cat((e3, d3), dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat((e2, d2), dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat((e1, d1), dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        output = self.tanh(self.out_conv(d1))\n",
    "        return output\n",
    "\n",
    "# --- 2B. Mô Hình Thử Nghiệm: Reversed Autoencoder (RA) ---\n",
    "class ReversedAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReversedAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1), nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 7))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 7), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# In tóm tắt kiến trúc để kiểm tra\n",
    "print(\"--- Kiến trúc U-Net ---\")\n",
    "summary(UNet().to(DEVICE), (1, IMG_SIZE, IMG_SIZE))\n",
    "print(\"\n--- Kiến trúc Reversed Autoencoder ---\")\n",
    "summary(ReversedAutoencoder().to(DEVICE), (1, IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 3: Logic Xử Lý Dữ Liệu\n",
    "**Mô tả:** Ô code này chứa logic để đọc metadata, phân chia dữ liệu và tạo ra các `DataLoader` để cung cấp dữ liệu cho mô hình trong quá trình huấn luyện và đánh giá.\n",
    "\n",
    "**Hướng dẫn:** Chạy ô này để chuẩn bị sẵn sàng các bộ dữ liệu. Sau khi chạy, bạn có thể thu gọn ô này lại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def get_data_loaders():\n",
    "    df = pd.read_csv(METADATA_PATH)\n",
    "    all_image_paths = glob.glob(os.path.join(IMAGE_DIR, '*.png'))\n",
    "    image_filenames = {os.path.basename(p): p for p in all_image_paths}\n",
    "    df['full_path'] = df['Image Index'].map(image_filenames)\n",
    "    df = df.dropna(subset=['full_path'])\n",
    "\n",
    "    normal_df = df[df['Finding Labels'] == 'No Finding'].sample(n=NUM_NORMAL_SAMPLES, random_state=42)\n",
    "    abnormal_df = df[df['Finding Labels'] != 'No Finding'].sample(n=NUM_ABNORMAL_SAMPLES, random_state=42)\n",
    "\n",
    "    train_df, val_df = train_test_split(normal_df, test_size=0.2, random_state=42)\n",
    "    test_normal_df = val_df.sample(n=int(len(val_df)*0.5), random_state=42)\n",
    "    test_df = pd.concat([test_normal_df, abnormal_df])\n",
    "\n",
    "    class ChestXrayDataset(Dataset):\n",
    "        def __init__(self, dataframe, transform):\n",
    "            self.dataframe = dataframe\n",
    "            self.transform = transform\n",
    "        def __len__(self): return len(self.dataframe)\n",
    "        def __getitem__(self, idx):\n",
    "            row = self.dataframe.iloc[idx]\n",
    "            image = Image.open(row['full_path']).convert(\"L\")\n",
    "            label = 0 if row['Finding Labels'] == 'No Finding' else 1\n",
    "            return self.transform(image), label\n",
    "\n",
    "    transform_set = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "    train_loader = DataLoader(ChestXrayDataset(train_df, transform_set), batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(ChestXrayDataset(val_df, transform_set), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(ChestXrayDataset(test_df, transform_set), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    print(f\"Đã tạo xong DataLoaders: Train={len(train_loader.dataset)}, Val={len(val_loader.dataset)}, Test={len(test_loader.dataset)}\")\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = get_data_loaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 4: Logic Huấn Luyện\n",
    "**Mô tả:** Ô code này định nghĩa hàm `train_model`, chứa logic huấn luyện có thể tái sử dụng cho bất kỳ mô hình nào. Hàm này sẽ thực hiện vòng lặp qua các epoch, tính toán loss, cập nhật trọng số và lưu lại phiên bản mô hình tốt nhất dựa trên validation loss.\n",
    "\n",
    "**Hướng dẫn:** Chạy ô này để khai báo hàm. Sau đó, bạn có thể thu gọn nó lại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, train_loader, val_loader, model_name):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    best_val_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for images, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "            images = images.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, _ in val_loader:\n",
    "                images = images.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, images)\n",
    "                running_val_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - {model_name} - Train Loss: {epoch_train_loss:.6f}, Val Loss: {epoch_val_loss:.6f}\")\n",
    "        \n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            save_path = os.path.join(SAVE_MODEL_DIR, f'{model_name}_best.pth')\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Lưu model tốt nhất tại: {save_path}\")\n",
    "            \n",
    "    print(f\"Hoàn tất huấn luyện {model_name}\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 5: Thực Thi Huấn Luyện\n",
    "**Mô tả:** Đây là khu vực thực thi chính. Các ô code dưới đây sẽ khởi tạo và huấn luyện lần lượt từng mô hình. Quá trình này sẽ tốn nhiều thời gian nhất.\n",
    "\n",
    "**Hướng dẫn:** Chạy lần lượt các ô để huấn luyện U-Net, sau đó đến Reversed Autoencoder, và cuối cùng là vẽ đồ thị loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5a. Huấn luyện mô hình U-Net\n",
    "print(\"--- Bắt đầu huấn luyện U-Net Baseline ---\")\n",
    "unet_model = UNet().to(DEVICE)\n",
    "unet_model, unet_history = train_model(unet_model, train_loader, val_loader, \"unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5b. Huấn luyện mô hình Reversed Autoencoder\n",
    "print(\"\n--- Bắt đầu huấn luyện Reversed Autoencoder ---\")\n",
    "ra_model = ReversedAutoencoder().to(DEVICE)\n",
    "ra_model, ra_history = train_model(ra_model, train_loader, val_loader, \"ra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5c. Vẽ đồ thị loss để so sánh quá trình học\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(unet_history['train_loss'], label='U-Net Train Loss')\n",
    "plt.plot(unet_history['val_loss'], label='U-Net Val Loss')\n",
    "plt.title('U-Net Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(ra_history['train_loss'], label='RA Train Loss')\n",
    "plt.plot(ra_history['val_loss'], label='RA Val Loss')\n",
    "plt.title('Reversed Autoencoder Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 6: Đánh Giá & Báo Cáo Kết Quả\n",
    "**Mô tả:** Sau khi các mô hình đã được huấn luyện, phần này sẽ tải lại phiên bản tốt nhất của chúng và thực hiện các phân tích so sánh.\n",
    "\n",
    "**Hướng dẫn:** Chạy các ô bên dưới để tính toán các chỉ số, vẽ biểu đồ và hiển thị các hình ảnh so sánh trực quan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6a. Định nghĩa các hàm hỗ trợ đánh giá\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model_performance(model, data_loader):\n",
    "    model.eval()\n",
    "    reconstruction_errors = []\n",
    "    true_labels = []\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            error = criterion(outputs, images).mean(dim=[1, 2, 3])\n",
    "            reconstruction_errors.extend(error.cpu().numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "    return np.array(reconstruction_errors), np.array(true_labels)\n",
    "\n",
    "def visualize_comparison(model1, model2, model1_name, model2_name, data_loader, num_images=5):\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    images, labels = next(iter(data_loader))\n",
    "    images = images.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs1 = model1(images).cpu()\n",
    "        outputs2 = model2(images).cpu()\n",
    "        error_map1 = torch.mean(nn.functional.mse_loss(outputs1, images.cpu(), reduction='none'), dim=1)\n",
    "        error_map2 = torch.mean(nn.functional.mse_loss(outputs2, images.cpu(), reduction='none'), dim=1)\n",
    "    \n",
    "    plt.figure(figsize=(25, num_images * 5))\n",
    "    for i in range(num_images):\n",
    "        label_text = \"Abnormal\" if labels[i] == 1 else \"Normal\"\n",
    "        img_display = images[i].cpu() * 0.5 + 0.5\n",
    "        recon1_display = outputs1[i] * 0.5 + 0.5\n",
    "        recon2_display = outputs2[i] * 0.5 + 0.5\n",
    "        \n",
    "        # Hiển thị 5 ảnh trên 1 hàng\n",
    "        plt.subplot(num_images, 5, i * 5 + 1); plt.imshow(img_display.squeeze(), cmap='gray'); plt.title(f\"Original ({label_text})\"); plt.axis('off')\n",
    "        plt.subplot(num_images, 5, i * 5 + 2); plt.imshow(recon1_display.squeeze(), cmap='gray'); plt.title(f\"{model1_name} Recon\"); plt.axis('off')\n",
    "        plt.subplot(num_images, 5, i * 5 + 3); plt.imshow(error_map1[i], cmap='jet'); plt.title(f\"{model1_name} Error Map\"); plt.axis('off')\n",
    "        plt.subplot(num_images, 5, i * 5 + 4); plt.imshow(recon2_display.squeeze(), cmap='gray'); plt.title(f\"{model2_name} Recon\"); plt.axis('off')\n",
    "        plt.subplot(num_images, 5, i * 5 + 5); plt.imshow(error_map2[i], cmap='jet'); plt.title(f\"{model2_name} Error Map\"); plt.axis('off')\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6b. Chạy đánh giá và tính toán chỉ số\n",
    "# Tải lại các model tốt nhất\n",
    "unet_eval = UNet().to(DEVICE)\n",
    "unet_eval.load_state_dict(torch.load(os.path.join(SAVE_MODEL_DIR, 'unet_best.pth')))\n",
    "\n",
    "ra_eval = ReversedAutoencoder().to(DEVICE)\n",
    "ra_eval.load_state_dict(torch.load(os.path.join(SAVE_MODEL_DIR, 'ra_best.pth')))\n",
    "\n",
    "print(\"Bắt đầu đánh giá U-Net...\")\n",
    "unet_errors, unet_labels = evaluate_model_performance(unet_eval, test_loader)\n",
    "unet_auc = roc_auc_score(unet_labels, unet_errors)\n",
    "\n",
    "print(\"Bắt đầu đánh giá Reversed Autoencoder...\")\n",
    "ra_errors, ra_labels = evaluate_model_performance(ra_eval, test_loader)\n",
    "ra_auc = roc_auc_score(ra_labels, ra_errors)\n",
    "\n",
    "print(\"--- KẾT QUẢ ĐÁNH GIÁ ---\")\n",
    "print(f\"AUC của U-Net: {unet_auc:.4f}\")\n",
    "print(f\"AUC của Reversed Autoencoder: {ra_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6c. Trực quan hóa kết quả so sánh\n",
    "# Vẽ đường cong ROC\n",
    "unet_fpr, unet_tpr, _ = roc_curve(unet_labels, unet_errors)\n",
    "ra_fpr, ra_tpr, _ = roc_curve(ra_labels, ra_errors)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(unet_fpr, unet_tpr, label=f'U-Net (AUC = {unet_auc:.4f})', linewidth=2)\n",
    "plt.plot(ra_fpr, ra_tpr, label=f'Reversed Autoencoder (AUC = {ra_auc:.4f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('So Sánh Đường Cong ROC', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Trực quan hóa hình ảnh so sánh\n",
    "print(\"\n--- So Sánh Trực Quan Trên Ảnh Test ---\")\n",
    "visualize_comparison(unet_eval, ra_eval, \"U-Net\", \"RA\", test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phần 7: Kết Luận Cuối Cùng\n",
    "**Mô tả:** Đây là phần cuối cùng, nơi bạn sẽ viết ra những phân tích và kết luận của mình dựa trên các kết quả đã được tạo ra ở trên.\n",
    "\n",
    "**Hướng dẫn:** Dựa vào điểm AUC và các hình ảnh so sánh, hãy trả lời các câu hỏi sau:\n",
    "1.  **Mô hình nào hoạt động hiệu quả hơn?** \n",
    "    *Phân tích của bạn ở đây. Ví dụ: Dựa trên kết quả, mô hình U-Net với AUC là [điền số] đã cho thấy hiệu suất vượt trội so với Reversed Autoencoder (AUC = [điền số])...*\n",
    "\n",
    "2.  **Tại sao mô hình đó lại hiệu quả hơn (dựa trên hình ảnh)?** \n",
    "    *Phân tích của bạn ở đây. Ví dụ: Khi quan sát các bản đồ lỗi, có thể thấy U-Net tạo ra các vùng lỗi tập trung và rõ nét hơn tại vị trí bất thường. Điều này có thể là do các kết nối tắt (skip connections) đã giúp U-Net tái tạo nền (background) của ảnh tốt hơn, từ đó làm nổi bật sự khác biệt do bệnh lý gây ra...*\n",
    "\n",
    "3.  **Hạn chế của nghiên cứu này là gì?** \n",
    "    *Phân tích của bạn ở đây. Ví dụ: Nghiên cứu được thực hiện trên một tập dữ liệu con và với số epoch giới hạn. Kết quả có thể được cải thiện hơn nữa nếu huấn luyện trên toàn bộ dữ liệu với thời gian dài hơn...*\n",
    "\n",
    "4.  **Hướng phát triển tiếp theo là gì?** \n",
    "    *Phân tích của bạn ở đây. Ví dụ: Các bước tiếp theo có thể bao gồm việc tinh chỉnh siêu tham số cho mô hình chiến thắng, thử nghiệm với các hàm loss khác nhau (như SSIM), và áp dụng mô hình lên các bộ dữ liệu khác (như MURA hoặc MRI) để kiểm tra khả năng tổng quát hóa...*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}